I210410 13:49:10.721513 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/10 13:49:10
I210410 13:49:10.721556 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹755e1052c718›
I210410 13:49:10.721591 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)
I210410 13:49:10.721603 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start-single-node --http-port 26256 --insecure]›
I210410 13:49:10.721623 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W210410 13:49:10.721192 1 cli/start.go:1143 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I210410 13:49:10.721778 1 cli/start.go:1153 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I210410 13:49:10.722278 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
W210410 13:49:10.722363 1 cli/start.go:987 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (1.9 GiB).›
I210410 13:49:10.722724 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 13:49:10.722747 1 cli/start.go:1168 ⋮ ‹CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)›
I210410 13:49:10.724399 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 13:49:10.724434 1 server/config.go:428 ⋮ system total memory: ‹7.6 GiB›
I210410 13:49:10.724459 1 server/config.go:430 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   1.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210410 13:49:10.724525 1 cli/start.go:965 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I210410 13:49:10.724548 1 cli/start.go:972 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I210410 13:49:10.728406 1 cli/start.go:511 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I210410 13:49:10.728471 1 cli/start.go:516 ⋮ starting cockroach node
I210410 13:49:11.314695 102 server/server.go:790 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210410 13:49:11.828829 102 server/config.go:619 ⋮ [n?] 1 storage engine‹› initialized
I210410 13:49:11.828923 102 server/config.go:622 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I210410 13:49:11.828958 102 server/config.go:622 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
I210410 13:49:11.874325 151 server/server.go:1424 ⋮ [n?] connecting to gossip network to verify cluster ID ‹"dd9dc586-c756-4f4b-a9e5-9e23cf559418"›
W210410 13:49:11.874592 102 cli/start.go:911 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"755e1052c718"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I210410 13:49:11.874736 102 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"755e1052c718:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.7" started_at:1618062551874725230 cluster_name:"" sql_address:<network_field:"tcp" address_field:"755e1052c718:26257" >›
W210410 13:49:11.889400 239 kv/kvserver/replica_range_lease.go:556 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 13:49:11.889672 151 server/server.go:1427 ⋮ [n1] node connected via gossip
W210410 13:49:11.889630 239 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 13:49:11.890708 102 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=196 GiB, available=4.3 GiB, used=4.5 MiB, logicalBytes=25 MiB), ranges=57, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=333.00 p90=42234.00 pMax=25468910.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I210410 13:49:11.891020 102 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
W210410 13:49:11.945466 239 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 13:49:12.039916 239 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 13:49:12.186846 102 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210410 13:49:12.186988 102 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I210410 13:49:12.187217 102 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I210410 13:49:12.187321 102 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210410 13:49:12.187416 102 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210410 13:49:12.187475 102 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210410 13:49:12.187562 102 server/server.go:1544 ⋮ [n1] starting http server at ‹[::]:26256› (use: ‹755e1052c718:26256›)
I210410 13:49:12.187673 102 server/server.go:1551 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210410 13:49:12.187777 102 server/server.go:1552 ⋮ [n1] advertising CockroachDB node at ‹755e1052c718:26257›
I210410 13:49:13.377271 102 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I210410 13:49:13.377565 328 sql/temporary_schema.go:510 ⋮ [n1] running temporary object cleanup background job
I210410 13:49:13.377732 102 server/server_sql.go:800 ⋮ [n1] done ensuring all necessary migrations have run
I210410 13:49:13.377762 102 server/server.go:1887 ⋮ [n1] serving sql connections
I210410 13:49:13.378485 102 cli/start.go:677 ⋮ [config] clusterID: ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
I210410 13:49:13.378587 102 cli/start.go:687 ⋮ node startup completed:
CockroachDB node starting at 2021-04-10 13:49:13.37783454 +0000 UTC (took 2.7s)
build:               CCL v20.2.7 @ 2021/03/29 17:52:00 (go1.13.14)
webui:               ‹http://755e1052c718:26256›
sql:                 ‹postgresql://root@755e1052c718:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=755e1052c718:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp793322045›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
nodeID:              1
I210410 13:49:13.383484 358 jobs/job_scheduler.go:349 ⋮ [n1] waiting 2m0s before scheduled jobs daemon start
I210410 13:49:13.389449 359 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
I210410 13:49:13.680221 328 sql/temporary_schema.go:545 ⋮ [n1] found 0 temporary schemas
I210410 13:49:13.680388 328 sql/temporary_schema.go:548 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I210410 13:49:13.680461 328 sql/temporary_schema.go:549 ⋮ [n1] completed temporary object cleanup job
I210410 13:49:13.680523 328 sql/temporary_schema.go:627 ⋮ [n1] temporary object cleaner next scheduled to run at 2021-04-10 14:19:13.377435164 +0000 UTC
I210410 13:49:13.913126 363 sql/catalog/lease/lease.go:2124 ⋮ released orphaned lease: ‹{id:52 version:1 expiration:{Time:{wall:517448000 ext:63753659619 loc:<nil>}}}›
I210410 13:49:13.921760 164 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 13:49:13.979598 164 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
I210410 13:49:13.979935 326 sql/sqlliveness/slstorage/slstorage.go:348 ⋮ [n1] inserted sqlliveness session ‹4ce892d39bfe4958a22d4a5c923a7410›
I210410 13:49:13.980099 326 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹4ce892d39bfe4958a22d4a5c923a7410›
I210410 13:49:14.137956 324 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:755e1052c718:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.7 StartedAt:1618062551874725230 LocalityAddress:[] ClusterName: SQLAddress:755e1052c718:26257} ClusterID:dd9dc586-c756-4f4b-a9e5-9e23cf559418 StartedAt:1618062551874725230 LastUp:1618062536883321491}›
W210410 13:49:16.061426 205 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r34/1:‹/Table/3{8-9}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 13:49:17.378466 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 13:49:17.621156 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r70/1:‹/Table/6{3-4}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 13:49:17.967425 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.279219118s; err=<nil>
I210410 13:49:22.192348 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 133 MiB RSS, 209 goroutines, 30 MiB/26 MiB/44 MiB GO alloc/idle/total, 10 MiB/20 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (12x), 11 KiB/27 KiB (r/w)net
W210410 13:49:22.226903 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.038702229s; err=<nil>
W210410 13:49:26.862660 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.173817675s; err=<nil>
W210410 13:49:30.951782 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/5{7-8}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 13:49:31.366520 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.178252825s; err=<nil>
I210410 13:49:32.190204 152 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 1M 1 ]: 1M›
I210410 13:49:32.190613 152 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2   532 K       -   530 K       -       -       -       -   532 K       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   1.1 M       -    84 K     0 B       0     0 B       0   1.1 M       1   1.1 M       1    12.9›
‹  total         1   1.1 M       -   532 K     0 B       0     0 B       0   1.6 M       1   1.1 M       1     3.0›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2   2.3 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        29   921 K   94.2%  (score == hit-rate)›
‹ tcache         1   616 B   99.8%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   86.0%  (score == utility)›
I210410 13:49:32.191482 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 137 MiB RSS, 209 goroutines, 28 MiB/28 MiB/45 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 13.6 CGO/sec, 2.5/0.9 %(u/s)time, 0.0 %gc (1x), 5.6 KiB/22 KiB (r/w)net
W210410 13:49:35.707464 197 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r22/1:‹/Table/2{6-7}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 13:49:35.835746 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.147458301s; err=<nil>
I210410 13:49:36.087671 325 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
W210410 13:49:41.044984 174 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r20/1:‹/Table/2{4-5}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
I210410 13:49:42.192549 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 140 MiB RSS, 209 goroutines, 18 MiB/36 MiB/46 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 0.5 CGO/sec, 3.6/0.5 %(u/s)time, 0.0 %gc (2x), 11 KiB/22 KiB (r/w)net
I210410 13:49:52.191884 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 141 MiB RSS, 206 goroutines, 30 MiB/26 MiB/46 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 0.1 CGO/sec, 3.1/0.7 %(u/s)time, 0.0 %gc (0x), 21 KiB/13 KiB (r/w)net
W210410 13:49:55.651880 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 13:49:55.951985 186 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 13:49:55.952045 192 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r82/1:‹/Table/6{7-8}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
I210410 13:49:57.836813 325 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
I210410 13:50:02.193139 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 142 MiB RSS, 206 goroutines, 29 MiB/27 MiB/47 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 0.1 CGO/sec, 3.1/0.9 %(u/s)time, 0.0 %gc (1x), 2.2 KiB/11 KiB (r/w)net
I210410 13:50:12.187423 153 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
  n1 [sentinel];
I210410 13:50:12.192341 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 143 MiB RSS, 206 goroutines, 26 MiB/29 MiB/48 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.2 %(u/s)time, 0.0 %gc (1x), 2.1 KiB/11 KiB (r/w)net
I210410 13:50:22.190381 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 145 MiB RSS, 206 goroutines, 24 MiB/32 MiB/49 MiB GO alloc/idle/total, 11 MiB/20 MiB CGO alloc/total, 0.1 CGO/sec, 4.0/1.5 %(u/s)time, 0.0 %gc (1x), 203 B/0 B (r/w)net
I210410 13:50:32.192510 157 server/status/runtime.go:525 ⋮ [n1] runtime stats: 146 MiB RSS, 205 goroutines, 32 MiB/25 MiB/49 MiB GO alloc/idle/total, 15 MiB/24 MiB CGO alloc/total, 0.2 CGO/sec, 2.4/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 13:50:38.980366 159 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.292094671s; err=<nil>
I210410 13:50:39.984970 1 cli/start.go:736 ⋮ received signal 'terminated'
I210410 13:50:39.985072 1 cli/start.go:821 ⋮ initiating graceful shutdown of server
I210410 13:50:40.336159 1780 server/drain.go:174 ⋮ [server drain process] drain remaining: 2
I210410 13:50:40.336218 1780 server/drain.go:176 ⋮ [server drain process] drain details: liveness record: 1, descriptor leases: 1
I210410 13:50:40.792156 1780 server/drain.go:174 ⋮ [server drain process] drain remaining: 0
I210410 13:50:40.792314 1780 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W210410 13:50:40.792507 326 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
W210410 13:50:40.793120 337 jobs/registry.go:675 ⋮ canceling all adopted jobs due to stopper quiescing
I210410 13:50:40.915872 1 cli/start.go:873 ⋮ server drained and shutdown completed
