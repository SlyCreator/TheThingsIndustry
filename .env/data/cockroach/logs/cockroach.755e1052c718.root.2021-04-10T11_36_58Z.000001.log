I210410 11:36:58.178999 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/10 11:36:58
I210410 11:36:58.179026 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹755e1052c718›
I210410 11:36:58.179043 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)
I210410 11:36:58.179058 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start-single-node --http-port 26256 --insecure]›
I210410 11:36:58.179083 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W210410 11:36:58.170851 1 cli/start.go:1143 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I210410 11:36:58.179310 1 cli/start.go:1153 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I210410 11:36:58.180067 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
W210410 11:36:58.194984 1 cli/start.go:987 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (1.9 GiB).›
I210410 11:36:58.195598 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 11:36:58.195633 1 cli/start.go:1168 ⋮ ‹CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)›
I210410 11:36:58.387255 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 11:36:58.387317 1 server/config.go:428 ⋮ system total memory: ‹7.6 GiB›
I210410 11:36:58.490445 1 server/config.go:430 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   1.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210410 11:36:58.490613 1 cli/start.go:965 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I210410 11:36:58.490669 1 cli/start.go:972 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I210410 11:36:58.886569 1 cli/start.go:511 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I210410 11:36:58.886687 1 cli/start.go:516 ⋮ starting cockroach node
I210410 11:37:01.332943 26 server/server.go:790 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210410 11:37:04.150144 26 server/config.go:619 ⋮ [n?] 1 storage engine‹› initialized
I210410 11:37:04.233755 26 server/config.go:622 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I210410 11:37:04.233798 26 server/config.go:622 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
W210410 11:37:04.624202 26 cli/start.go:911 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"755e1052c718"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I210410 11:37:04.624221 168 server/server.go:1424 ⋮ [n?] connecting to gossip network to verify cluster ID ‹"dd9dc586-c756-4f4b-a9e5-9e23cf559418"›
I210410 11:37:04.624545 26 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"755e1052c718:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.7" started_at:1618054624624528778 cluster_name:"" sql_address:<network_field:"tcp" address_field:"755e1052c718:26257" >›
I210410 11:37:05.654853 168 server/server.go:1427 ⋮ [n1] node connected via gossip
W210410 11:37:05.759352 265 kv/kvserver/replica_range_lease.go:556 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 11:37:05.759629 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 11:37:05.803781 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 11:37:05.901546 26 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=196 GiB, available=4.4 GiB, used=3.1 MiB, logicalBytes=15 MiB), ranges=106, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=41.00 p90=8439.00 pMax=14878636.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
W210410 11:37:05.913214 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 11:37:05.918074 26 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
I210410 11:37:06.086557 26 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210410 11:37:06.086675 26 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I210410 11:37:06.086856 26 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I210410 11:37:06.086927 26 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210410 11:37:06.086994 26 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210410 11:37:06.087029 26 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210410 11:37:06.087092 26 server/server.go:1544 ⋮ [n1] starting http server at ‹[::]:26256› (use: ‹755e1052c718:26256›)
I210410 11:37:06.087169 26 server/server.go:1551 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210410 11:37:06.087237 26 server/server.go:1552 ⋮ [n1] advertising CockroachDB node at ‹755e1052c718:26257›
W210410 11:37:06.098600 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 11:37:06.505686 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 11:37:07.278694 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.191294834s; err=<nil>
I210410 11:37:08.131401 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 11:37:08.358169 171 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
W210410 11:37:09.242520 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:37:09.242928 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:37:09.462573 354 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r70/1:‹/Table/63{-/2}›] slow heartbeat took 1.022164212s; err=<nil>
W210410 11:37:09.462590 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r20/1:‹/Table/2{4-5}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:37:09.462680 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:37:09.462869 26 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I210410 11:37:09.615706 26 server/server_sql.go:800 ⋮ [n1] done ensuring all necessary migrations have run
I210410 11:37:09.615809 26 server/server.go:1887 ⋮ [n1] serving sql connections
I210410 11:37:09.616202 26 cli/start.go:677 ⋮ [config] clusterID: ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
I210410 11:37:09.616354 26 cli/start.go:687 ⋮ node startup completed:
CockroachDB node starting at 2021-04-10 11:37:09.615962044 +0000 UTC (took 11.5s)
build:               CCL v20.2.7 @ 2021/03/29 17:52:00 (go1.13.14)
webui:               ‹http://755e1052c718:26256›
sql:                 ‹postgresql://root@755e1052c718:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=755e1052c718:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp606508286›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
nodeID:              1
I210410 11:37:09.631132 584 jobs/job_scheduler.go:349 ⋮ [n1] waiting 2m0s before scheduled jobs daemon start
I210410 11:37:09.711073 570 sql/temporary_schema.go:510 ⋮ [n1] running temporary object cleanup background job
W210410 11:37:10.570940 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r72/1:‹/Table/63/{2-3}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:37:10.748180 558 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] slow heartbeat took 1.035671235s; err=<nil>
W210410 11:37:11.011671 617 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r72/1:‹/Table/63/{2-3}›] slow heartbeat took 1.128245574s; err=<nil>
I210410 11:37:11.320227 570 sql/temporary_schema.go:545 ⋮ [n1] found 0 temporary schemas
I210410 11:37:11.320331 570 sql/temporary_schema.go:548 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I210410 11:37:11.320381 570 sql/temporary_schema.go:549 ⋮ [n1] completed temporary object cleanup job
I210410 11:37:11.320418 570 sql/temporary_schema.go:627 ⋮ [n1] temporary object cleaner next scheduled to run at 2021-04-10 12:07:09.596462211 +0000 UTC
I210410 11:37:11.627801 585 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
W210410 11:37:11.959375 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.371781729s; err=<nil>
W210410 11:37:12.433500 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:37:12.833617 369 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] slow heartbeat took 1.65591765s; err=<nil>
W210410 11:37:13.000348 625 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r27/1:‹/{NamespaceTab…-Table/32}›] slow heartbeat took 1.822625082s; err=<nil>
W210410 11:37:13.290024 337 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] slow heartbeat took 2.03550582s; err=<nil>
W210410 11:37:13.401221 643 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] slow heartbeat took 2.081190801s; err=<nil>
W210410 11:37:13.668256 81 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 2.347496596s; err=<nil>
I210410 11:37:13.802408 711 sql/catalog/lease/lease.go:2124 ⋮ released orphaned lease: ‹{id:52 version:1 expiration:{Time:{wall:127224000 ext:63753651422 loc:<nil>}}}›
W210410 11:37:13.879782 707 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r73/1:‹/Table/6{3/3-4}›] slow heartbeat took 2.434779158s; err=<nil>
I210410 11:37:14.280958 566 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:755e1052c718:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.7 StartedAt:1618054624624528778 LocalityAddress:[] ClusterName: SQLAddress:755e1052c718:26257} ClusterID:dd9dc586-c756-4f4b-a9e5-9e23cf559418 StartedAt:1618054624624528778 LastUp:1618054368953327218}›
I210410 11:37:14.615150 568 sql/sqlliveness/slstorage/slstorage.go:348 ⋮ [n1] inserted sqlliveness session ‹8e424d29d5a64767851d3b68e5d71b11›
I210410 11:37:14.615260 568 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹8e424d29d5a64767851d3b68e5d71b11›
I210410 11:37:16.090922 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 132 MiB RSS, 213 goroutines, 23 MiB/34 MiB/43 MiB GO alloc/idle/total, 73 MiB/81 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (17x), 8.4 KiB/3.4 KiB (r/w)net
I210410 11:37:26.087588 111 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 787K 1 ]: 787K›
I210410 11:37:26.087862 111 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2   553 K       -   549 K       -       -       -       -   553 K       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   787 K       -   325 K     0 B       0     0 B       0   787 K       1   938 K       1     2.4›
‹  total         1   787 K       -   553 K     0 B       0     0 B       0   1.3 M       1   938 K       1     2.4›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2    64 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        35   1.1 M   97.3%  (score == hit-rate)›
‹ tcache         1   616 B   99.9%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   72.6%  (score == utility)›
I210410 11:37:26.088857 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 133 MiB RSS, 207 goroutines, 22 MiB/33 MiB/43 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 1.3 CGO/sec, 2.9/1.2 %(u/s)time, 0.0 %gc (1x), 9.7 KiB/22 KiB (r/w)net
W210410 11:37:27.802227 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:37:27.958203 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r67/1:‹/Table/62/{2-3}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:37:28.414799 958 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r67/1:‹/Table/62/{2-3}›] slow heartbeat took 1.422287356s; err=<nil>
W210410 11:37:29.606010 1091 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r98/1:‹/Table/71{-/2}›] slow heartbeat took 1.001428655s; err=<nil>
W210410 11:37:32.292499 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
I210410 11:37:32.293006 567 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
W210410 11:37:32.963026 1122 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r46/1:‹/Table/56{-/2}›] slow heartbeat took 2.095552399s; err=<nil>
W210410 11:37:32.963123 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W210410 11:37:33.171580 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:37:33.171604 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:37:35.887454 1130 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r84/1:‹/Table/68{-/2}›] slow heartbeat took 1.486570975s; err=<nil>
I210410 11:37:36.089414 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 135 MiB RSS, 209 goroutines, 30 MiB/26 MiB/44 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:37:36.476886 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:37:36.476671 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:37:36.611873 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r84/1:‹/Table/68{-/2}›] handle raft ready: 0.7s [applied=3, batches=2, state_assertions=0]
W210410 11:37:39.891275 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 3.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:42.087723 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500171749s; err=context deadline exceeded
W210410 11:37:42.087900 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:37:44.693932 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 5.4s [applied=1, batches=1, state_assertions=0]
W210410 11:37:44.693975 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 5.2s [applied=1, batches=1, state_assertions=0]
W210410 11:37:44.693976 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 7.5s [applied=1, batches=1, state_assertions=0]
W210410 11:37:44.693977 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r12/1:‹/Table/1{6-7}›] handle raft ready: 5.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:44.695188 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 5.4s [applied=1, batches=1, state_assertions=0]
W210410 11:37:46.041096 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 11:37:46.091220 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 137 MiB RSS, 217 goroutines, 25 MiB/30 MiB/47 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 11.9 CGO/sec, 2.4/0.5 %(u/s)time, 0.0 %gc (1x), 214 B/0 B (r/w)net
W210410 11:37:46.588288 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500224347s; err=context deadline exceeded
W210410 11:37:46.588443 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:37:51.088794 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500223283s; err=context deadline exceeded
W210410 11:37:51.088982 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:37:52.681920 1205 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r94/1:‹/Table/70/{3-4}›] slow heartbeat took 16.069202993s; err=<nil>
W210410 11:37:52.681890 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r56/1:‹/Table/60{-/2}›] handle raft ready: 9.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:52.682012 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 12.8s [applied=1, batches=1, state_assertions=0]
W210410 11:37:52.682162 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 11.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:52.682215 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r10/1:‹/Table/1{4-5}›] handle raft ready: 8.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:52.682196 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r25/1:‹/{Table/29-NamespaceTab…}›] handle raft ready: 10.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.644501 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 9.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:53.644487 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 9.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:53.644604 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 9.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:53.644648 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] handle raft ready: 1.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.644497 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r77/1:‹/Table/65{-/2}›] handle raft ready: 8.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.644630 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r51/1:‹/Table/58{-/2}›] handle raft ready: 4.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.644808 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 8.9s [applied=1, batches=1, state_assertions=0]
W210410 11:37:53.644827 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 5.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.644936 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r30/1:‹/Table/3{4-5}›] handle raft ready: 3.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:53.645058 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r34/1:‹/Table/3{8-9}›] handle raft ready: 2.8s [applied=2, batches=1, state_assertions=0]
W210410 11:37:55.589370 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500246648s; err=context deadline exceeded
W210410 11:37:55.589520 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:37:55.596872 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r94/1:‹/Table/70/{3-4}›] handle raft ready: 2.9s [applied=3, batches=2, state_assertions=0]
I210410 11:37:56.089883 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 137 MiB RSS, 223 goroutines, 30 MiB/26 MiB/47 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/0.4 %(u/s)time, 0.0 %gc (0x), 70 B/0 B (r/w)net
W210410 11:37:57.238255 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
W210410 11:37:57.238355 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
W210410 11:37:57.238417 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
W210410 11:37:57.580833 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r39/1:‹/Table/5{3/4-4}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 11:37:57.580896 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r81/1:‹/Table/6{6/3-7}›] handle raft ready: 1.7s [applied=2, batches=1, state_assertions=0]
W210410 11:37:57.581144 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:59.276412 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:37:59.575639 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
I210410 11:37:59.846209 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618054661.840637257,0 is behind by 18.005570528s
W210410 11:37:59.992702 1150 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r84/1:‹/Table/68{-/2}›] slow heartbeat took 14.287007849s; err=<nil>
W210410 11:37:59.992827 1314 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 14.150380317s; err=<nil>
W210410 11:37:59.992963 1313 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 10.740021071s; err=<nil>
W210410 11:37:59.993059 1117 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 10.524013513s; err=<nil>
W210410 11:38:00.089787 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500134205s; err=context deadline exceeded
W210410 11:38:00.089851 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:38:00.144678 1401 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 6.499216786s; err=<nil>
W210410 11:38:00.570559 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:00.570552 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:00.570784 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:00.708397 1358 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r94/1:‹/Table/70/{3-4}›] slow heartbeat took 5.111264568s; err=<nil>
W210410 11:38:00.708602 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r84/1:‹/Table/68{-/2}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:00.708796 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 11:38:00.893696 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 11:38:03.077689 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:38:03.077730 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:38:03.077733 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r95/1:‹/Table/70/{4-5}›] handle raft ready: 1.8s [applied=2, batches=1, state_assertions=0]
W210410 11:38:04.842682 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.752776328s; err=<nil>
W210410 11:38:04.843280 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 3.4s [applied=1, batches=1, state_assertions=0]
W210410 11:38:04.843341 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r103/1:‹/Table/73/{2-3}›] handle raft ready: 3.0s [applied=2, batches=1, state_assertions=0]
W210410 11:38:04.843298 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:04.843887 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 3.4s [applied=2, batches=2, state_assertions=0]
W210410 11:38:04.842740 1510 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] slow heartbeat took 4.697715865s; err=<nil>
W210410 11:38:04.977309 1478 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r95/1:‹/Table/70/{4-5}›] slow heartbeat took 3.915620121s; err=<nil>
W210410 11:38:04.977445 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 11:38:04.977531 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 11:38:04.977560 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r91/1:‹/Table/{69/5-70}›] handle raft ready: 1.1s [applied=2, batches=1, state_assertions=0]
W210410 11:38:06.069903 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r55/1:‹/Table/{59/3-60}›] handle raft ready: 1.2s [applied=2, batches=1, state_assertions=0]
W210410 11:38:06.069883 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:38:06.069881 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:38:06.070094 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
I210410 11:38:06.086858 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
  n1 [sentinel];
I210410 11:38:06.089331 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 140 MiB RSS, 213 goroutines, 26 MiB/28 MiB/48 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.3/0.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:38:07.349709 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r95/1:‹/Table/70/{4-5}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 11:38:07.349997 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 11:38:07.350216 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r79/1:‹/Table/66{-/2}›] handle raft ready: 1.5s [applied=2, batches=1, state_assertions=0]
W210410 11:38:07.350405 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:38:07.352003 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.4s [applied=2, batches=1, state_assertions=0]
W210410 11:38:08.287720 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:08.287729 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W210410 11:38:08.287813 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r50/1:‹/Table/5{7/3-8}›] handle raft ready: 1.4s [applied=2, batches=1, state_assertions=0]
W210410 11:38:08.287863 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r21/1:‹/Table/2{5-6}›] handle raft ready: 2.0s [applied=2, batches=1, state_assertions=0]
W210410 11:38:08.832480 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W210410 11:38:08.832501 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W210410 11:38:08.832579 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.5s [applied=2, batches=1, state_assertions=0]
W210410 11:38:11.005627 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.7s [applied=1, batches=1, state_assertions=0]
W210410 11:38:11.459615 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r83/1:‹/Table/6{7/2-8}›] handle raft ready: 2.6s [applied=2, batches=1, state_assertions=0]
W210410 11:38:11.459615 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:11.459783 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 6.616692548s; err=<nil>
W210410 11:38:11.459756 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:11.459965 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:11.459983 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r65/1:‹/Table/6{1/3-2}›] handle raft ready: 1.6s [applied=2, batches=1, state_assertions=0]
W210410 11:38:11.460533 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 1.8s [applied=2, batches=1, state_assertions=0]
W210410 11:38:11.639358 1568 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r51/1:‹/Table/58{-/2}›] slow heartbeat took 5.569085861s; err=<nil>
W210410 11:38:11.860119 1438 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r21/1:‹/Table/2{5-6}›] slow heartbeat took 5.770589926s; err=<nil>
W210410 11:38:12.364503 1634 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r63/1:‹/Table/61{-/2}›] slow heartbeat took 5.014396079s; err=<nil>
W210410 11:38:12.364698 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r21/1:‹/Table/2{5-6}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:38:13.364254 1640 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] slow heartbeat took 3.850936535s; err=<nil>
W210410 11:38:13.364381 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.90452488s; err=<nil>
W210410 11:38:13.364527 1599 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r30/1:‹/Table/3{4-5}›] slow heartbeat took 1.280904812s; err=<nil>
W210410 11:38:13.850060 1617 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] slow heartbeat took 1.481954087s; err=<nil>
W210410 11:38:14.090039 1692 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r64/1:‹/Table/61/{2-3}›] slow heartbeat took 1.229114443s; err=<nil>
W210410 11:38:15.140873 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.553402499s; err=<nil>
W210410 11:38:15.140919 1746 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r34/1:‹/Table/3{8-9}›] slow heartbeat took 1.290509759s; err=<nil>
W210410 11:38:15.463969 1739 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r44/1:‹/Table/55/{2-3}›] slow heartbeat took 1.093719889s; err=<nil>
I210410 11:38:16.090226 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 144 MiB RSS, 217 goroutines, 37 MiB/19 MiB/51 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:38:16.301444 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:38:16.413408 1706 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648754936359649281: stepping through state running with error: <nil>
W210410 11:38:16.568765 1772 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r22/1:‹/Table/2{6-7}›] slow heartbeat took 1.248711911s; err=<nil>
W210410 11:38:16.680600 1696 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] slow heartbeat took 1.215960777s; err=<nil>
W210410 11:38:17.882329 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r11/1:‹/Table/1{5-6}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:38:17.882301 1814 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r45/1:‹/Table/5{5/3-6}›] slow heartbeat took 2.11603179s; err=<nil>
W210410 11:38:17.882594 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:38:18.175435 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:38:18.175435 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.4s [applied=2, batches=1, state_assertions=0]
W210410 11:38:18.175562 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r102/1:‹/Table/73{-/2}›] handle raft ready: 1.3s [applied=2, batches=1, state_assertions=0]
W210410 11:38:18.175726 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:19.499519 1860 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] slow heartbeat took 1.065944693s; err=<nil>
W210410 11:38:20.201843 1879 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r56/1:‹/Table/60{-/2}›] slow heartbeat took 1.150783108s; err=<nil>
W210410 11:38:21.600101 1845 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r10/1:‹/Table/1{4-5}›] slow heartbeat took 1.15242332s; err=<nil>
W210410 11:38:21.600144 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:38:21.860265 1926 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r93/1:‹/Table/70/{2-3}›] slow heartbeat took 1.359967064s; err=<nil>
W210410 11:38:23.551233 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.021872 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.022064 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r77/1:‹/Table/65{-/2}›] handle raft ready: 2.3s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.603345 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.603353 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.603424 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r14/1:‹/Table/1{8-9}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 11:38:25.759866 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 11:38:25.760199 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:38:25.971826 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.384353533s; err=<nil>
I210410 11:38:26.092298 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 147 MiB RSS, 216 goroutines, 37 MiB/19 MiB/53 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 4.3/0.7 %(u/s)time, 0.0 %gc (1x), 87 B/0 B (r/w)net
W210410 11:38:26.285178 1953 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r90/1:‹/Table/69/{4-5}›] slow heartbeat took 3.122948317s; err=<nil>
W210410 11:38:26.575388 1992 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r81/1:‹/Table/6{6/3-7}›] slow heartbeat took 1.552129107s; err=<nil>
W210410 11:38:27.654858 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:38:27.768937 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r107/1:‹/{Table/74/2-Max}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:38:27.769092 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:38:28.013689 1915 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r91/1:‹/Table/{69/5-70}›] slow heartbeat took 1.437436897s; err=<nil>
W210410 11:38:28.225362 1917 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r39/1:‹/Table/5{3/4-4}›] slow heartbeat took 1.404135075s; err=<nil>
W210410 11:38:28.448451 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.360833855s; err=<nil>
I210410 11:38:29.919435 1706 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648754936359649281: stepping through state succeeded with error: <nil>
W210410 11:38:30.365387 2058 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r41/1:‹/Table/54/{2-3}›] slow heartbeat took 1.013396847s; err=<nil>
W210410 11:38:30.988741 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r11/1:‹/Table/1{5-6}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:38:30.989303 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 11:38:31.212714 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r41/1:‹/Table/54/{2-3}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:38:32.350300 2153 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r89/1:‹/Table/69/{3-4}›] slow heartbeat took 1.136787621s; err=<nil>
W210410 11:38:32.350372 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:38:32.350358 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:38:32.539603 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r11/1:‹/Table/1{5-6}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:38:32.539602 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:32.750834 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.163195586s; err=<nil>
I210410 11:38:33.554780 2106 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648754992483139585: stepping through state running with error: <nil>
W210410 11:38:35.965084 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r11/1:‹/Table/1{5-6}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:38:35.965108 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:38:36.092365 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 149 MiB RSS, 213 goroutines, 39 MiB/17 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 5.1/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:38:36.389856 2228 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r52/1:‹/Table/5{8/2-9}›] slow heartbeat took 1.160035423s; err=<nil>
W210410 11:38:39.177554 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:38:39.913487 2370 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r54/1:‹/Table/59/{2-3}›] slow heartbeat took 1.03591476s; err=<nil>
W210410 11:38:41.497962 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:41.642614 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 11:38:41.642656 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r82/1:‹/Table/67{-/2}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:38:41.786967 2324 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r55/1:‹/Table/{59/3-60}›] slow heartbeat took 1.605219388s; err=<nil>
W210410 11:38:42.065393 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.477902398s; err=<nil>
W210410 11:38:43.115463 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
I210410 11:38:43.115649 2106 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648754992483139585: stepping through state succeeded with error: <nil>
W210410 11:38:43.390624 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 11:38:43.391057 155 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:38:43.679984 2327 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r43/1:‹/Table/55{-/2}›] slow heartbeat took 1.614191807s; err=<nil>
I210410 11:38:46.092800 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 150 MiB RSS, 207 goroutines, 36 MiB/21 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 5.0/0.9 %(u/s)time, 0.0 %gc (1x), 214 B/0 B (r/w)net
W210410 11:38:46.488789 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r83/1:‹/Table/6{7/2-8}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:38:46.792461 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r80/1:‹/Table/66/{2-3}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:38:49.343111 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:38:49.710719 2430 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r78/1:‹/Table/6{5/2-6}›] slow heartbeat took 2.220892719s; err=<nil>
I210410 11:38:56.092285 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 150 MiB RSS, 205 goroutines, 25 MiB/28 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.1 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:39:06.087090 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:39:06.092886 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 151 MiB RSS, 205 goroutines, 33 MiB/22 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.5 %(u/s)time, 0.0 %gc (0x), 70 B/0 B (r/w)net
W210410 11:39:08.659547 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.071934899s; err=<nil>
W210410 11:39:11.076005 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r33/1:‹/Table/3{7-8}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:39:16.090883 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 206 goroutines, 23 MiB/31 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.8 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:39:17.643636 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.05608726s; err=<nil>
I210410 11:39:26.093432 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 206 goroutines, 32 MiB/24 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:39:29.868036 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:39:30.033826 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:39:31.202563 2974 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r37/1:‹/Table/53/{2-3}›] slow heartbeat took 1.058046021s; err=<nil>
I210410 11:39:36.092757 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 206 goroutines, 22 MiB/31 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.9 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:39:39.051024 3180 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r50/1:‹/Table/5{7/3-8}›] slow heartbeat took 1.200853369s; err=<nil>
I210410 11:39:46.091100 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 205 goroutines, 31 MiB/25 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:39:49.221356 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.133811784s; err=<nil>
W210410 11:39:49.924142 3364 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r80/1:‹/Table/66/{2-3}›] slow heartbeat took 1.605752797s; err=<nil>
W210410 11:39:49.932120 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:50.248138 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 11:39:50.584239 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:50.584325 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:50.584459 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r80/1:‹/Table/66/{2-3}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:51.007585 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:39:51.341444 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:39:51.341501 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:39:51.719803 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:52.053942 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:52.443156 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:53.923351 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.335780326s; err=<nil>
W210410 11:39:54.268706 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:39:55.203621 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:39:55.515364 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:55.915715 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:39:56.093308 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 209 goroutines, 21 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/0.6 %(u/s)time, 0.0 %gc (1x), 1.4 KiB/0 B (r/w)net
W210410 11:39:56.305142 3450 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r36/1:‹/Table/53{-/2}›] slow heartbeat took 2.717823458s; err=<nil>
W210410 11:39:56.305526 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 11:39:56.684118 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:39:57.041786 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r36/1:‹/Table/53{-/2}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:57.408835 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:57.787172 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:58.154331 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:58.488543 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:58.833227 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:39:59.300400 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.212756217s; err=<nil>
W210410 11:39:59.300478 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:00.557899 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:01.034732 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:01.687387 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:02.195109 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:02.195089 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:40:02.550651 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:02.984333 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:02.984721 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:03.374062 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:40:03.796397 3536 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r79/1:‹/Table/66{-/2}›] slow heartbeat took 2.752614895s; err=<nil>
W210410 11:40:03.796725 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 11:40:04.230100 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:04.619178 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.031621201s; err=<nil>
W210410 11:40:04.619495 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r79/1:‹/Table/66{-/2}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:04.898891 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:40:06.086989 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:40:06.093559 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:40:07.302210 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:07.912851 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.82532354s; err=<nil>
W210410 11:40:08.369394 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:08.902949 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:40:09.437120 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:40:09.942755 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:10.404919 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:10.404942 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:10.905784 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:11.417163 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:11.417157 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:11.850799 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:12.395425 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:12.395723 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:12.951085 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:13.451223 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:14.007095 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:40:14.474223 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:15.363778 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.776198698s; err=<nil>
W210410 11:40:15.753020 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
I210410 11:40:16.093808 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 209 goroutines, 36 MiB/20 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:40:16.153192 3597 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r102/1:‹/Table/73{-/2}›] slow heartbeat took 5.531018414s; err=<nil>
W210410 11:40:16.676261 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:17.132443 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r102/1:‹/Table/73{-/2}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:17.523425 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:17.523537 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:17.912907 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:18.490671 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:18.490774 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:40:18.935910 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.572023301s; err=<nil>
W210410 11:40:18.936096 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=2, batches=2, state_assertions=0]
W210410 11:40:20.294270 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:20.595025 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:20.973048 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:20.973504 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:21.362566 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:21.362556 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:21.751745 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.164146509s; err=<nil>
W210410 11:40:21.751816 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:21.752035 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:22.131312 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:40:22.131339 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:22.510981 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:22.900860 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:22.900862 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:40:23.583046 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:23.928524 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:24.341797 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.8s [applied=3, batches=1, state_assertions=0]
W210410 11:40:25.100165 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:40:25.446149 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:25.735882 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.6s [applied=3, batches=1, state_assertions=0]
W210410 11:40:26.049424 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.961830893s; err=<nil>
W210410 11:40:26.049806 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
I210410 11:40:26.093849 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 208 goroutines, 26 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:40:26.362277 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:28.075157 154 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:40:28.587869 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:40:28.957202 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:29.336815 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:29.615578 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:30.007814 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:40:30.007968 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:30.342297 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:30.609526 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.021912861s; err=<nil>
W210410 11:40:30.609472 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:30.609840 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
W210410 11:40:30.909746 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:33.723280 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:34.512817 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 11:40:34.934987 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.847360911s; err=<nil>
W210410 11:40:34.935146 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:40:35.313059 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 11:40:36.094058 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 206 goroutines, 33 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.7 %(u/s)time, 0.0 %gc (0x), 87 B/0 B (r/w)net
W210410 11:40:39.461329 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.873650215s; err=<nil>
W210410 11:40:40.133112 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:40:40.501300 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:40:40.501324 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:40:40.836163 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:41.215301 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:40:41.215358 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:40:46.094199 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 205 goroutines, 21 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.3 %(u/s)time, 1.8 %gc (1x), 0 B/0 B (r/w)net
I210410 11:40:56.094128 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 155 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.4 %(u/s)time, 0.0 %gc (0x), 214 B/0 B (r/w)net
I210410 11:41:06.087058 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:41:06.094805 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 155 MiB RSS, 205 goroutines, 34 MiB/21 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:41:16.095091 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 206 goroutines, 25 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.7 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:41:20.463936 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 11:41:26.095216 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 208 goroutines, 33 MiB/23 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.4 %(u/s)time, 0.0 %gc (0x), 70 B/0 B (r/w)net
I210410 11:41:36.095347 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 206 goroutines, 21 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:41:46.095953 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:41:56.095764 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 205 goroutines, 35 MiB/21 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:42:06.087129 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:42:06.095895 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 205 goroutines, 24 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:42:16.093913 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 206 goroutines, 33 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:42:26.094028 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 206 goroutines, 21 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/0.3 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:42:36.094281 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 206 goroutines, 29 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.3/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:42:46.098108 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 205 goroutines, 34 MiB/23 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.3 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:42:56.098042 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 205 goroutines, 27 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:43:06.087095 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:43:06.100623 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 205 goroutines, 34 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:43:16.100791 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 206 goroutines, 24 MiB/30 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.8/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:43:26.100595 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 206 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:43:36.100877 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 206 goroutines, 21 MiB/31 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.7 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:43:46.098964 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:43:56.099755 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 207 goroutines, 36 MiB/20 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.1/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:43:56.490104 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:43:56.932392 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.344901202s; err=<nil>
W210410 11:44:01.016549 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:44:02.492441 154 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 3.0s [applied=1, batches=1, state_assertions=0]
W210410 11:44:02.492525 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:44:02.946435 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 11:44:02.946422 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:44:03.216083 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:44:03.216110 154 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:44:03.216619 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:44:03.477196 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:44:03.477298 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:44:03.706943 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.619442436s; err=<nil>
I210410 11:44:06.086878 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:44:06.099563 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 205 goroutines, 24 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:44:11.460918 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:44:12.570768 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:44:14.338894 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:44:14.757447 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:15.029725 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 11:44:15.298678 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.711065524s; err=<nil>
W210410 11:44:15.299064 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
I210410 11:44:16.101886 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 207 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:44:19.104752 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.017279401s; err=<nil>
I210410 11:44:26.099642 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 207 goroutines, 21 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.2 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:44:27.498203 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:44:30.098152 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:30.319850 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:30.736892 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:44:31.127005 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:31.716997 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:44:31.716969 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:44:31.717010 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:44:31.717011 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:44:35.551754 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:35.551795 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 3.8s [applied=2, batches=1, state_assertions=0]
W210410 11:44:35.552184 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 3.8s [applied=3, batches=1, state_assertions=0]
I210410 11:44:36.100542 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 217 goroutines, 29 MiB/25 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.6 %(u/s)time, 0.0 %gc (0x), 1.9 KiB/0 B (r/w)net
W210410 11:44:36.425148 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 4.1s [applied=1, batches=1, state_assertions=0]
W210410 11:44:36.623325 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 11:44:36.659660 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:44:36.659667 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:44:36.659685 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r88/1:‹/Table/69/{2-3}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:44:36.659875 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
I210410 11:44:36.872763 278 kv/kvserver/node_liveness.go:1131 ⋮ [n1,liveness-hb] retrying liveness update after ‹kvserver.errRetryLiveness›: ‹result is ambiguous (context deadline exceeded)›
W210410 11:44:36.872920 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 5.285376473s; err=context deadline exceeded
W210410 11:44:36.872973 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:44:38.037024 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.163957806s; err=<nil>
I210410 11:44:46.100171 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 206 goroutines, 20 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:44:56.101833 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 205 goroutines, 27 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.8 %(u/s)time, 0.0 %gc (0x), 87 B/0 B (r/w)net
I210410 11:45:06.086866 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:45:06.100389 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 205 goroutines, 34 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:45:08.209920 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 11:45:08.241432 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
I210410 11:45:16.102141 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 207 goroutines, 26 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/0.5 %(u/s)time, 0.0 %gc (1x), 214 B/0 B (r/w)net
I210410 11:45:26.102463 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 206 goroutines, 32 MiB/23 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:45:27.631929 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:45:27.762818 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.175241684s; err=<nil>
W210410 11:45:29.626223 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:45:29.867580 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:45:29.867761 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:29.873468 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:30.174790 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:45:30.457949 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:30.457982 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:45:30.457998 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:30.680512 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:45:31.214539 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.126898362s; err=<nil>
W210410 11:45:31.337298 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:35.837800 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.250187517s; err=<nil>
I210410 11:45:36.179530 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 207 goroutines, 21 MiB/31 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.9 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:45:39.792687 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:45:39.981001 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:45:39.981538 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:45:42.350846 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:42.826907 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.73938133s; err=<nil>
W210410 11:45:42.826982 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.8s [applied=1, batches=1, state_assertions=0]
W210410 11:45:42.827055 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:45:42.827042 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:45:42.827167 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.8s [applied=2, batches=2, state_assertions=0]
W210410 11:45:43.055794 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:45:43.446881 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:43.446890 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:45:43.446944 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:45:44.508943 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:45:44.710301 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.122755784s; err=<nil>
I210410 11:45:46.101478 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:45:49.435083 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.347521673s; err=<nil>
I210410 11:45:56.228170 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 205 goroutines, 35 MiB/21 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:46:06.087038 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:46:06.101238 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 147 MiB RSS, 205 goroutines, 23 MiB/30 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.1/0.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:46:07.169969 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.082422068s; err=<nil>
W210410 11:46:07.393825 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:46:10.084766 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:10.551566 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:46:12.129974 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:46:12.129991 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:46:12.667951 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.061115 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 11:46:13.061189 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.351623 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.351897 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.613422 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.613451 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:13.871902 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.284327046s; err=<nil>
W210410 11:46:13.872057 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
I210410 11:46:16.104036 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 142 MiB RSS, 206 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.4 %(u/s)time, 0.0 %gc (0x), 70 B/0 B (r/w)net
W210410 11:46:18.917202 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:46:19.969526 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:20.489890 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:46:20.493401 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:46:21.002751 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:46:21.574039 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:46:21.574072 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:46:21.727101 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:22.143868 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.556392512s; err=<nil>
W210410 11:46:22.144215 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:22.144570 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
W210410 11:46:24.434118 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:46:25.337858 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:46:25.627496 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.539927472s; err=<nil>
W210410 11:46:25.627611 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:25.838936 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:46:26.102080 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 129 MiB RSS, 206 goroutines, 37 MiB/19 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:46:31.126256 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:46:31.389859 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:31.389856 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 11:46:31.634666 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:46:36.101530 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 126 MiB RSS, 206 goroutines, 27 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.0/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:46:38.548986 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.4s [applied=2, batches=1, state_assertions=0]
W210410 11:46:41.499222 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:46:41.499234 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W210410 11:46:41.499327 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:46:41.505444 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W210410 11:46:41.802759 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:46:42.670348 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 11:46:42.869797 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:46:42.869830 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:46:42.869872 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:46:42.869815 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:46:43.704180 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r94/1:‹/Table/70/{3-4}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:46:43.704113 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 6.116612968s; err=<nil>
W210410 11:46:43.704500 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.9s [applied=2, batches=2, state_assertions=0]
I210410 11:46:46.105192 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 120 MiB RSS, 214 goroutines, 34 MiB/21 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:46:46.519641 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:46.519731 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
W210410 11:46:48.204462 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.499572671s; err=context deadline exceeded
W210410 11:46:48.204532 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:46:49.084369 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r94/1:‹/Table/70/{3-4}›] handle raft ready: 5.4s [applied=1, batches=1, state_assertions=0]
W210410 11:46:49.084531 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.0s [applied=1, batches=1, state_assertions=0]
W210410 11:46:49.084315 8554 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 6.757518061s; err=heartbeat failed on epoch increment
E210410 11:46:49.311379 8554 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] heartbeat failed on epoch increment
W210410 11:46:50.787686 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:46:50.787658 8597 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r72/1:‹/Table/63/{2-3}›] slow heartbeat took 7.918190877s; err=heartbeat failed on epoch increment
E210410 11:46:50.787769 8597 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r72/1:‹/Table/63/{2-3}›] heartbeat failed on epoch increment
W210410 11:46:52.704698 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.50011437s; err=context deadline exceeded
W210410 11:46:52.704761 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:46:53.441070 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:46:54.763953 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
I210410 11:46:56.104086 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 110 MiB RSS, 219 goroutines, 39 MiB/18 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.2/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:46:57.204944 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500135965s; err=context deadline exceeded
W210410 11:46:57.205040 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:46:58.581003 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 5.1s [applied=1, batches=1, state_assertions=0]
W210410 11:47:00.168152 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 5.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:01.705330 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500234434s; err=context deadline exceeded
W210410 11:47:01.705512 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:47:03.122432 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 4.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:04.774962 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 4.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.006807 8675 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r96/1:‹/Table/70/{5-6}›] slow heartbeat took 18.135973366s; err=<nil>
W210410 11:47:06.006880 8643 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 16.749513176s; err=<nil>
W210410 11:47:06.006991 8712 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 16.654269172s; err=<nil>
W210410 11:47:06.007103 8692 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 16.534433934s; err=<nil>
I210410 11:47:06.086890 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
W210410 11:47:06.205874 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500206718s; err=context deadline exceeded
W210410 11:47:06.206041 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

I210410 11:47:06.220560 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 221 goroutines, 22 MiB/30 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.3 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:47:06.295325 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.295756 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.638266 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r96/1:‹/Table/70/{5-6}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.638138 8695 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r65/1:‹/Table/6{1/3-2}›] slow heartbeat took 15.85019239s; err=heartbeat failed on epoch increment
W210410 11:47:06.638321 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.638354 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
E210410 11:47:06.638476 8695 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r65/1:‹/Table/6{1/3-2}›] heartbeat failed on epoch increment
W210410 11:47:06.638561 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:06.877904 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:07.980222 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.774003162s; err=<nil>
I210410 11:47:07.879690 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618055203.271992833,0 is behind by 24.60769193s
W210410 11:47:08.264959 8776 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r96/1:‹/Table/70/{5-6}›] slow heartbeat took 1.626325022s; err=<nil>
W210410 11:47:08.586238 8851 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 1.947538558s; err=<nil>
W210410 11:47:09.005013 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r96/1:‹/Table/70/{5-6}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:09.302879 8743 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 2.664161251s; err=<nil>
W210410 11:47:09.303009 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:09.613792 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r96/1:‹/Table/70/{5-6}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:09.865295 8777 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 3.226381727s; err=<nil>
W210410 11:47:09.865450 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:09.998803 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:10.602646 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:10.611493 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:10.611724 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:10.840236 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:11.181930 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:11.182026 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:11.182151 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:11.525490 8908 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r17/1:‹/Table/2{1-2}›] slow heartbeat took 2.519235506s; err=<nil>
W210410 11:47:11.525568 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.438057028s; err=<nil>
W210410 11:47:11.525703 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=2, batches=2, state_assertions=0]
W210410 11:47:12.555912 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:12.556015 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:12.559650 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.4s [applied=2, batches=1, state_assertions=0]
W210410 11:47:12.559834 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:12.759293 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r17/1:‹/Table/2{1-2}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:47:13.370014 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.7s [applied=3, batches=1, state_assertions=0]
W210410 11:47:13.865468 155 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:13.865657 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 11:47:13.865717 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
I210410 11:47:16.104885 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 220 goroutines, 32 MiB/23 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:47:16.234027 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:16.234423 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:18.087797 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500300423s; err=context deadline exceeded
W210410 11:47:18.088061 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:47:18.154148 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 4.3s [applied=1, batches=1, state_assertions=0]
W210410 11:47:18.154244 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:18.664250 8995 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r18/1:‹/Table/2{2-3}›] slow heartbeat took 5.904234696s; err=<nil>
W210410 11:47:18.664532 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:18.664616 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 2.4s [applied=4, batches=1, state_assertions=0]
W210410 11:47:19.050348 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.050537 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.417115 8911 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r9/1:‹/Table/1{3-4}›] slow heartbeat took 6.0494511s; err=<nil>
W210410 11:47:19.417298 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.417310 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r18/1:‹/Table/2{2-3}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.711665 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.997891 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.997923 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:19.998215 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r9/1:‹/Table/1{3-4}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:20.257992 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:20.257990 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:47:20.773865 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:20.774291 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:21.287881 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:21.288219 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:21.288184 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:21.655598 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:21.655800 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:22.135198 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:22.545765 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:22.780799 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:23.059159 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.970947009s; err=<nil>
W210410 11:47:23.456848 8991 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] slow heartbeat took 1.575985236s; err=<nil>
W210410 11:47:24.002151 8993 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r61/1:‹/Table/60/{6-7}›] slow heartbeat took 1.993134489s; err=<nil>
I210410 11:47:26.314338 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 213 goroutines, 38 MiB/18 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:47:26.091078 111 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 787K 1 ]: 787K›
I210410 11:47:26.461774 111 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2    16 M       -    16 M       -       -       -       -    16 M       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   787 K       -   325 K     0 B       0     0 B       0   787 K       1   938 K       1     2.4›
‹  total         1   787 K       -    16 M     0 B       0     0 B       0    16 M       1   938 K       1     1.0›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2    64 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        35   1.1 M   99.2%  (score == hit-rate)›
‹ tcache         1   616 B  100.0%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   72.6%  (score == utility)›
W210410 11:47:30.441506 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] handle raft ready: 7.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:32.695069 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 7.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:32.695263 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r61/1:‹/Table/60/{6-7}›] handle raft ready: 8.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:32.695072 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 8.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:32.760204 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 9.7009758s; err=context deadline exceeded
W210410 11:47:32.760366 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:47:33.046919 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] handle raft ready: 2.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:33.301560 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r61/1:‹/Table/60/{6-7}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:33.301561 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:47:33.301568 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:47:34.124122 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:34.124631 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:35.369958 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 11:47:35.488932 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618055240.484289431,0 is behind by 15.004637149s
I210410 11:47:36.219616 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 103 MiB RSS, 218 goroutines, 24 MiB/27 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:47:36.933222 9110 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 7.219364833s; err=<nil>
W210410 11:47:36.933434 9149 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 6.308801192s; err=<nil>
W210410 11:47:36.933303 9039 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] slow heartbeat took 6.491467757s; err=<nil>
W210410 11:47:36.934071 9224 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r61/1:‹/Table/60/{6-7}›] slow heartbeat took 4.238367444s; err=<nil>
W210410 11:47:36.934591 9234 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 4.238838787s; err=<nil>
W210410 11:47:36.933128 9087 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 7.635047827s; err=<nil>
W210410 11:47:37.395223 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.634715753s; err=<nil>
W210410 11:47:38.104477 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r13/1:‹/Table/1{7-8}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.104514 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.104544 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.104719 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.104801 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r61/1:‹/Table/60/{6-7}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.104963 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.462007 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.821059 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.821094 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.821290 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:38.827708 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:39.339058 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.943685721s; err=<nil>
W210410 11:47:39.339327 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:39.339352 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:39.339495 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
W210410 11:47:39.872469 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:47:40.408652 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:40.917551 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:47:40.917759 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:41.174638 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:47:41.463829 239 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:41.464074 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:41.915213 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:42.378860 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.79123615s; err=<nil>
W210410 11:47:42.622002 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:43.201268 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 11:47:46.104957 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 100 MiB RSS, 207 goroutines, 33 MiB/21 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:47:47.253559 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:48.134960 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:47:48.326654 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:47:49.893802 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 11:47:50.541099 251 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W210410 11:47:51.437099 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:51.437136 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W210410 11:47:51.437148 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 11:47:51.437211 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:51.437549 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
I210410 11:47:51.585103 278 kv/kvserver/node_liveness.go:1131 ⋮ [n1,liveness-hb] retrying liveness update after ‹kvserver.errRetryLiveness›: ‹result is ambiguous (context deadline exceeded)›
W210410 11:47:52.125439 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 7.03786509s; err=context deadline exceeded
W210410 11:47:52.125550 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:47:54.183084 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:54.183064 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.7s [applied=1, batches=1, state_assertions=0]
I210410 11:47:56.105117 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 93 MiB RSS, 216 goroutines, 38 MiB/18 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.8/1.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:47:56.625896 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500216545s; err=context deadline exceeded
W210410 11:47:56.626122 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:47:59.143589 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 7.7s [applied=1, batches=1, state_assertions=0]
W210410 11:47:59.143644 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 7.0s [applied=1, batches=1, state_assertions=0]
W210410 11:47:59.143555 9401 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 7.706369411s; err=heartbeat failed on epoch increment
W210410 11:47:59.143927 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] handle raft ready: 7.7s [applied=1, batches=1, state_assertions=0]
E210410 11:47:59.143935 9401 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] heartbeat failed on epoch increment
W210410 11:47:59.144327 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 6.5s [applied=1, batches=1, state_assertions=0]
W210410 11:48:01.238539 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500185449s; err=context deadline exceeded
W210410 11:48:01.238726 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:48:01.519003 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 5.7s [applied=1, batches=1, state_assertions=0]
W210410 11:48:01.835903 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.7s [applied=2, batches=2, state_assertions=0]
W210410 11:48:01.835732 9337 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 10.398421517s; err=heartbeat failed on epoch increment
W210410 11:48:01.835912 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.7s [applied=3, batches=2, state_assertions=0]
E210410 11:48:01.836031 9337 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] heartbeat failed on epoch increment
W210410 11:48:02.331659 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 11:48:01.836084 9402 kv/txn.go:750 ⋮ [n1] async rollback failed: ‹result is ambiguous (context deadline exceeded)›
W210410 11:48:02.915215 9479 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] slow heartbeat took 11.477873322s; err=heartbeat failed on epoch increment
E210410 11:48:02.915447 9479 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] heartbeat failed on epoch increment
W210410 11:48:03.060337 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:48:03.233879 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 11:48:03.774167 9405 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 7.616596785s; err=<nil>
W210410 11:48:03.774406 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.460451417s; err=<nil>
W210410 11:48:03.774294 9354 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 4.629859779s; err=<nil>
W210410 11:48:03.774535 9575 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 1.93792546s; err=<nil>
W210410 11:48:03.774635 9338 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 1.937958654s; err=<nil>
W210410 11:48:04.227959 9599 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r56/1:‹/Table/60{-/2}›] slow heartbeat took 1.312036433s; err=<nil>
W210410 11:48:04.717487 9504 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] slow heartbeat took 1.801561743s; err=<nil>
W210410 11:48:05.265921 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:48:05.513061 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.738544383s; err=<nil>
I210410 11:48:06.087006 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:48:06.232931 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 96 MiB RSS, 209 goroutines, 25 MiB/27 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 5.6/1.3 %(u/s)time, 1.9 %gc (1x), 0 B/0 B (r/w)net
W210410 11:48:06.443042 9614 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] slow heartbeat took 1.043841659s; err=<nil>
W210410 11:48:07.742811 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:48:08.290331 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=2, batches=1, state_assertions=0]
W210410 11:48:08.813446 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:48:11.228961 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:48:11.229123 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:48:12.358075 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 11:48:12.360660 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 3.1s [applied=1, batches=1, state_assertions=0]
W210410 11:48:13.479129 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 5.891567893s; err=<nil>
W210410 11:48:13.479197 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.3s [applied=1, batches=1, state_assertions=0]
W210410 11:48:13.479320 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.3s [applied=2, batches=2, state_assertions=0]
W210410 11:48:14.471784 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:48:14.471783 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.226090 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.226165 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.483477 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.743175 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.743224 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:48:15.743285 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:48:16.105498 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 97 MiB RSS, 208 goroutines, 32 MiB/22 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:48:16.332645 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.853427919s; err=<nil>
W210410 11:48:16.332932 153 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
W210410 11:48:17.289217 151 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:48:17.600977 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.013425166s; err=<nil>
I210410 11:48:26.106043 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 95 MiB RSS, 213 goroutines, 38 MiB/17 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:48:34.875734 9988 server/node_engine_health.go:72 ⋮ [n1] disk stall detected: unable to write to ‹<no-attributes>=/cockroach/cockroach-data› within 10s ‹›

‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2    17 M       -    17 M       -       -       -       -    17 M       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   787 K       -   325 K     0 B       0     0 B       0   787 K       1   938 K       1     2.4›
‹  total         1   787 K       -    17 M     0 B       0     0 B       0    18 M       1   938 K       1     1.0›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2    64 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        35   1.1 M   99.2%  (score == hit-rate)›
‹ tcache         1   616 B  100.0%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   72.6%  (score == utility)›
I210410 11:48:36.105284 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 96 MiB RSS, 221 goroutines, 41 MiB/15 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.1/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:48:45.043495 271 kv/kvserver/store_rebalancer.go:223 ⋮ [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I210410 11:48:46.106893 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 221 goroutines, 24 MiB/28 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/0.8 %(u/s)time, 1.5 %gc (1x), 0 B/0 B (r/w)net
W210410 11:48:50.064319 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 11:48:56.106530 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 103 MiB RSS, 221 goroutines, 25 MiB/27 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.0/0.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:49:06.086942 112 gossip/gossip.go:568 ⋮ [n1] gossip status (stalled, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
I210410 11:49:06.105074 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 100 MiB RSS, 222 goroutines, 26 MiB/26 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.8/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:49:16.107521 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 100 MiB RSS, 226 goroutines, 27 MiB/26 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
E210410 11:49:19.848358 562 kv/kvserver/replica_write.go:222 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] range unavailable: ‹have been waiting 60.00s for proposing command Put [/System/StatusNode/1,/Min).›
‹This range is likely unavailable.›
‹Please submit this message to Cockroach Labs support along with the following information:›

‹Descriptor:  r3:{-} [(n1,s1):1, next=2, gen=0]›
‹Live:        ›
‹Non-live:    (n1,s1):1›
‹Raft Status: {"id":"1","term":9,"vote":"1","commit":1351,"lead":"1","raftState":"StateLeader","applied":1349,"progress":{"1":{"match":1351,"next":1352,"state":"StateReplicate"}},"leadtransferee":"0"}›

‹and a copy of https://yourhost:8080/#/reports/range/3›

‹If you are using CockroachDB Enterprise, reach out through your›
‹support contract. Otherwise, please open an issue at:›

‹  https://github.com/cockroachdb/cockroach/issues/new/choose›
W210410 11:49:21.073218 9822 kv/kvserver/spanlatch/manager.go:396 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] have been waiting 1m0s to acquire latch ‹/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0@0,0›, held by ‹/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0@1618055300.989161584,0›
E210410 11:49:21.123209 568 kv/kvserver/replica_write.go:222 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] range unavailable: ‹have been waiting 60.00s for proposing command [txn: fa13adbc], EndTxn(commit:true) [/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0] .›
‹This range is likely unavailable.›
‹Please submit this message to Cockroach Labs support along with the following information:›

‹Descriptor:  r35:{-} [(n1,s1):1, next=2, gen=1]›
‹Live:        ›
‹Non-live:    (n1,s1):1›
‹Raft Status: {"id":"1","term":9,"vote":"1","commit":3945,"lead":"1","raftState":"StateLeader","applied":3943,"progress":{"1":{"match":3945,"next":3946,"state":"StateReplicate"}},"leadtransferee":"0"}›

‹and a copy of https://yourhost:8080/#/reports/range/35›

‹If you are using CockroachDB Enterprise, reach out through your›
‹support contract. Otherwise, please open an issue at:›

‹  https://github.com/cockroachdb/cockroach/issues/new/choose›
W210410 11:49:21.993840 9821 kv/kvserver/spanlatch/manager.go:396 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] have been waiting 1m0s to acquire latch ‹/Local/Range/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0/Transaction/"fa13adbc-ed7f-4f78-89b6-3b6a6e352404"@0,0›, held by ‹/Local/Range/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0/Transaction/"fa13adbc-ed7f-4f78-89b6-3b6a6e352404"@0,0›
W210410 11:49:22.552186 9789 kv/kvserver/spanlatch/manager.go:396 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] have been waiting 1m0s to acquire latch ‹/Table/39/{1-2}@1618055302.551384896,0›, held by ‹/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0@1618055300.989161584,0›
E210410 11:49:22.836196 9875 kv/kvserver/replica_write.go:222 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] range unavailable: ‹have been waiting 60.00s for proposing command RequestLease [/Min,/Min).›
‹This range is likely unavailable.›
‹Please submit this message to Cockroach Labs support along with the following information:›

‹Descriptor:  r1:{-} [(n1,s1):1, next=2, gen=0]›
‹Live:        ›
‹Non-live:    (n1,s1):1›
‹Raft Status: {"id":"1","term":9,"vote":"1","commit":1925,"lead":"1","raftState":"StateLeader","applied":1923,"progress":{"1":{"match":1925,"next":1926,"state":"StateReplicate"}},"leadtransferee":"0"}›

‹and a copy of https://yourhost:8080/#/reports/range/1›

‹If you are using CockroachDB Enterprise, reach out through your›
‹support contract. Otherwise, please open an issue at:›

‹  https://github.com/cockroachdb/cockroach/issues/new/choose›
W210410 11:49:25.828103 9879 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,merge,s1,r36/1:‹/Table/53{-/2}›] have been waiting 1m0s attempting to acquire lease
I210410 11:49:25.828381 9879 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,merge,s1,r36/1:‹/Table/53{-/2}›] slow lease acquisition finished after 1m0.000341404s with error ‹[NotLeaseHolderError] r36: replica (n1,s1):1 not lease holder; lease holder unknown› after 1 attempts
W210410 11:49:25.890216 9880 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r36/1:‹/Table/53{-/2}›] slow heartbeat took 1m0.000338913s; err=context canceled
E210410 11:49:25.890399 9880 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r36/1:‹/Table/53{-/2}›] context canceled
I210410 11:49:26.104860 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 101 MiB RSS, 231 goroutines, 28 MiB/25 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:49:27.334999 264 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] have been waiting 1m0s attempting to acquire lease
W210410 11:49:27.520563 9923 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] have been waiting 1m0s attempting to acquire lease
I210410 11:49:27.520730 9923 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] slow lease acquisition finished after 1m0.000282632s with error ‹[NotLeaseHolderError] r24: replica (n1,s1):1 not lease holder; lease holder unknown› after 1 attempts
W210410 11:49:27.735415 9923 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] slow range RPC: ‹have been waiting 60.00s (1 attempts) for RPC TruncateLog [/Table/28,/Min) to r24:/Table/2{8-9} [(n1,s1):1, next=2, gen=0]; resp: aborted during DistSender.Send: context deadline exceeded›
W210410 11:49:27.735492 9923 kv/kvclient/kvcoord/dist_sender.go:1507 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] slow RPC response: ‹slow RPC finished after 60.22s (1 attempts)›
E210410 11:49:27.963474 9923 kv/kvserver/queue.go:1087 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] ‹operation "raftlog queue process replica 24" timed out after 1m0s›
W210410 11:49:29.266312 277 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] have been waiting 1m0s attempting to acquire lease
W210410 11:49:34.096162 9973 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:49:34.276571 9758 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
I210410 11:49:36.108099 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 232 goroutines, 29 MiB/24 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:49:40.443319 9965 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:49:41.965890 271 kv/kvserver/store_rebalancer.go:223 ⋮ [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I210410 11:49:46.133427 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 231 goroutines, 30 MiB/23 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:49:50.084457 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 11:49:56.105934 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 231 goroutines, 31 MiB/23 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.3 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:05.585344 265 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:50:05.585357 266 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] have been waiting 1m0s attempting to acquire lease
E210410 11:50:05.586485 10202 kv/kvserver/replica_write.go:222 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] range unavailable: ‹have been waiting 60.00s for proposing command RequestLease [/System/NodeLiveness,/Min).›
‹This range is likely unavailable.›
‹Please submit this message to Cockroach Labs support along with the following information:›

‹Descriptor:  r2:{-} [(n1,s1):1, next=2, gen=0]›
‹Live:        ›
‹Non-live:    (n1,s1):1›
‹Raft Status: {"id":"1","term":9,"vote":"1","commit":3109,"lead":"1","raftState":"StateLeader","applied":3107,"progress":{"1":{"match":3109,"next":3110,"state":"StateReplicate"}},"leadtransferee":"0"}›

‹and a copy of https://yourhost:8080/#/reports/range/2›

‹If you are using CockroachDB Enterprise, reach out through your›
‹support contract. Otherwise, please open an issue at:›

‹  https://github.com/cockroachdb/cockroach/issues/new/choose›
I210410 11:50:06.086836 112 gossip/gossip.go:568 ⋮ [n1] gossip status (stalled, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:50:06.105530 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 231 goroutines, 32 MiB/22 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.8/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:12.155892 10265 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:50:14.027956 10189 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
I210410 11:50:16.105596 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 233 goroutines, 32 MiB/21 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:18.076209 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 118.6s [applied=1, batches=1, state_assertions=0]
I210410 11:50:18.076374 562 kv/kvserver/replica_write.go:181 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow command ‹Put [/System/StatusNode/1,/Min)› finished after 118.59s with error ‹<nil>›
W210410 11:50:18.610921 562 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,summaries] slow range RPC: ‹have been waiting 119.09s (1 attempts) for RPC Put [/System/StatusNode/1,/Min) to r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.PutResponse›
W210410 11:50:19.232780 10266 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:50:19.232798 10411 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] have been waiting 1m0s attempting to acquire lease
W210410 11:50:23.100194 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 120.3s [applied=1, batches=1, state_assertions=0]
W210410 11:50:23.100271 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 122.1s [applied=1, batches=1, state_assertions=0]
I210410 11:50:23.100548 9875 kv/kvserver/replica_write.go:181 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] slow command ‹RequestLease [/Min,/Min)› finished after 120.26s with error ‹<nil>›
W210410 11:50:23.100587 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 77.5s [applied=1, batches=1, state_assertions=0]
W210410 11:50:23.100639 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2m2.013178433s; err=context deadline exceeded
I210410 11:50:23.100695 264 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] slow lease acquisition finished after 1m55.765790429s with error ‹<nil>› after 1 attempts
W210410 11:50:23.100760 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

I210410 11:50:23.100858 10202 kv/kvserver/replica_write.go:181 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] slow command ‹RequestLease [/System/NodeLiveness,/Min)› finished after 77.51s with error ‹<nil>›
I210410 11:50:23.101032 266 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] slow lease acquisition finished after 1m17.515879089s with error ‹<nil>› after 1 attempts
W210410 11:50:23.101268 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 123.5s [applied=1, batches=1, state_assertions=0]
W210410 11:50:23.101571 9822 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,txn=‹fa13adbc›] slow range RPC: ‹have been waiting 122.11s (1 attempts) for RPC [txn: fa13adbc], QueryIntent [/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0,/Min) to r35:/Table/{39-53} [(n1,s1):1, next=2, gen=1]; resp: (err: <nil>), *roachpb.QueryIntentResponse›
W210410 11:50:23.537674 10368 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,raftlog,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow range RPC: ‹have been waiting 60.00s (1 attempts) for RPC TruncateLog [/System/NodeLivenessMax,/Min) to r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, next=2, gen=0]; resp: aborted during DistSender.Send: context deadline exceeded›
W210410 11:50:23.537813 10368 kv/kvclient/kvcoord/dist_sender.go:1507 ⋮ [n1,raftlog,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow RPC response: ‹slow RPC finished after 60.00s (1 attempts)›
E210410 11:50:23.537894 10368 kv/kvserver/queue.go:1087 ⋮ [n1,raftlog,s1,r3/1:‹/System/{NodeLive…-tsd}›] ‹operation "raftlog queue process replica 3" timed out after 1m0s›
W210410 11:50:25.828765 10192 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,merge,s1,r89/1:‹/Table/69/{3-4}›] have been waiting 1m0s attempting to acquire lease
I210410 11:50:25.829052 10192 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,merge,s1,r89/1:‹/Table/69/{3-4}›] slow lease acquisition finished after 1m0.000469587s with error ‹[NotLeaseHolderError] r89: replica (n1,s1):1 not lease holder; lease holder unknown› after 1 attempts
I210410 11:50:26.105485 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 234 goroutines, 35 MiB/19 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.0/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:26.588225 10456 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,replicate,s1,r24/1:‹/Table/2{8-9}›] have been waiting 1m0s attempting to acquire lease
I210410 11:50:26.588388 10456 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,replicate,s1,r24/1:‹/Table/2{8-9}›] slow lease acquisition finished after 1m0.000263317s with error ‹[NotLeaseHolderError] r24: replica (n1,s1):1 not lease holder; lease holder unknown› after 1 attempts
W210410 11:50:27.235720 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 9.2s [applied=1, batches=1, state_assertions=0]
W210410 11:50:27.538237 10478 kv/kvserver/replica_range_lease.go:1080 ⋮ [n1,gc,s1,r23/1:‹/Table/2{7-8}›] have been waiting 1m0s attempting to acquire lease
I210410 11:50:27.538711 10478 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,gc,s1,r23/1:‹/Table/2{7-8}›] slow lease acquisition finished after 1m0.000674294s with error ‹[NotLeaseHolderError] r23: replica (n1,s1):1 not lease holder; lease holder unknown› after 1 attempts
W210410 11:50:27.538726 10479 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] slow heartbeat took 1m0.000641102s; err=context canceled
E210410 11:50:27.538936 10479 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] context canceled
W210410 11:50:27.601077 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500182741s; err=context deadline exceeded
W210410 11:50:27.601251 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:28.658781 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 5.6s [applied=1, batches=1, state_assertions=0]
W210410 11:50:28.658873 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 5.6s [applied=1, batches=1, state_assertions=0]
W210410 11:50:28.658792 9851 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r89/1:‹/Table/69/{3-4}›] slow heartbeat took 2m2.138419274s; err=context canceled
I210410 11:50:28.658920 568 kv/kvserver/replica_write.go:181 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow command ‹[txn: fa13adbc], EndTxn(commit:true) [/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0]› finished after 127.67s with error ‹<nil>›
W210410 11:50:28.658798 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 5.6s [applied=2, batches=1, state_assertions=0]
E210410 11:50:28.659008 9851 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r89/1:‹/Table/69/{3-4}›] context canceled
W210410 11:50:28.658967 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 5.6s [applied=1, batches=1, state_assertions=0]
W210410 11:50:28.659229 568 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,txn=‹fa13adbc›] slow range RPC: ‹have been waiting 127.67s (1 attempts) for RPC [txn: fa13adbc], EndTxn(commit:true) [/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0]  to r35:/Table/{39-53} [(n1,s1):1, next=2, gen=1]; resp: (err: <nil>), *roachpb.EndTxnResponse›
W210410 11:50:28.659659 9821 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,txn-hb=‹fa13adbc›] slow range RPC: ‹have been waiting 126.67s (1 attempts) for RPC [txn: fa13adbc], HeartbeatTxn [/Table/39/1/"\x8eBM)զGg\x85\x1d;h\xe5\xd7\x1b\x11"/0,/Min) to r35:/Table/{39-53} [(n1,s1):1, next=2, gen=1]; resp: (err: result is ambiguous (context canceled))›
W210410 11:50:28.659761 9821 kv/kvclient/kvcoord/dist_sender.go:1507 ⋮ [n1,txn-hb=‹fa13adbc›] slow RPC response: ‹slow RPC finished after 126.67s (1 attempts)›
W210410 11:50:28.760393 9859 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,raftlog,s1,r4/1:‹/System{/tsd-tse}›] slow range RPC: ‹have been waiting 129.10s (1 attempts) for RPC TruncateLog [/System/tsd,/Min) to r4:/System{/tsd-tse} [(n1,s1):1, next=2, gen=0]; resp: (err: result is ambiguous (context deadline exceeded))›
W210410 11:50:28.760499 9859 kv/kvclient/kvcoord/dist_sender.go:1507 ⋮ [n1,raftlog,s1,r4/1:‹/System{/tsd-tse}›] slow RPC response: ‹slow RPC finished after 129.20s (1 attempts)›
E210410 11:50:28.760570 9859 kv/kvserver/queue.go:1087 ⋮ [n1,raftlog,s1,r4/1:‹/System{/tsd-tse}›] ‹operation "raftlog queue process replica 4" timed out after 1m0s›
W210410 11:50:30.366551 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:30.366616 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:30.366898 247 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
I210410 11:50:31.304625 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 11:50:31.558921 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:50:31.559200 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:50:32.101622 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500187967s; err=context deadline exceeded
W210410 11:50:32.101768 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:35.222276 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
I210410 11:50:36.106107 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 232 goroutines, 36 MiB/18 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.7/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:36.602096 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.50019298s; err=context deadline exceeded
W210410 11:50:36.602272 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:37.047978 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 5.5s [applied=2, batches=1, state_assertions=0]
I210410 11:50:37.501128 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618055300.056086828,0 is behind by 2m17.44503904s
W210410 11:50:41.102437 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500087254s; err=context deadline exceeded
W210410 11:50:41.102510 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:41.888421 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 6.3s [applied=1, batches=1, state_assertions=0]
W210410 11:50:43.005316 9924 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] slow heartbeat took 2m15.484845153s; err=<nil>
W210410 11:50:43.005365 9943 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 2m13.739184116s; err=<nil>
W210410 11:50:43.005433 9974 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 2m8.909818859s; err=<nil>
W210410 11:50:43.005703 10369 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 1m19.468301815s; err=<nil>
W210410 11:50:43.005768 11027 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 19.904432749s; err=<nil>
W210410 11:50:43.005820 11065 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] slow heartbeat took 17.176483744s; err=<nil>
W210410 11:50:43.005870 11068 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] slow heartbeat took 16.417306361s; err=<nil>
W210410 11:50:45.398262 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.5s [applied=1, batches=1, state_assertions=0]
I210410 11:50:46.108154 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 232 goroutines, 21 MiB/29 MiB/53 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.2 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:50:47.421925 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 6.319367328s; err=context deadline exceeded
W210410 11:50:47.421997 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 4.3s [applied=1, batches=1, state_assertions=0]
W210410 11:50:47.422042 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 4.3s [applied=1, batches=1, state_assertions=0]
W210410 11:50:47.422068 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] handle raft ready: 4.2s [applied=1, batches=1, state_assertions=0]
W210410 11:50:47.422148 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:47.422220 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 4.4s [applied=1, batches=1, state_assertions=0]
W210410 11:50:47.422330 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 4.4s [applied=1, batches=1, state_assertions=0]
I210410 11:50:47.422447 9973 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 2m13.326875728s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422505 10411 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 1m28.189946099s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422464 9965 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 2m6.979230906s with error ‹<nil>› after 1 attempts
W210410 11:50:47.422043 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 4.3s [applied=1, batches=1, state_assertions=0]
I210410 11:50:47.422560 9758 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 2m13.146144866s with error ‹<nil>› after 1 attempts
W210410 11:50:47.422041 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] handle raft ready: 4.2s [applied=1, batches=1, state_assertions=0]
I210410 11:50:47.422604 10265 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 1m35.266830516s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422613 10266 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 1m28.190044318s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422697 277 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow lease acquisition finished after 2m18.156571686s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422719 10189 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 1m33.395010174s with error ‹<nil>› after 1 attempts
I210410 11:50:47.422685 265 kv/kvserver/replica_range_lease.go:1085 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow lease acquisition finished after 1m41.837580437s with error ‹<nil>› after 1 attempts
W210410 11:50:49.031733 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 3.6s [applied=1, batches=1, state_assertions=0]
I210410 11:50:49.105741 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 11:50:50.104552 172 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 11:50:51.167203 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167179 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167215 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167299 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167182 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167417 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.167621 258 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 3.7s [applied=1, batches=1, state_assertions=0]
W210410 11:50:51.922555 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500201047s; err=context deadline exceeded
W210410 11:50:51.922705 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:53.135623 271 kv/kvserver/store_rebalancer.go:223 ⋮ [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I210410 11:50:56.106221 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 236 goroutines, 22 MiB/29 MiB/53 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.0/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:50:56.423030 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500152725s; err=context deadline exceeded
W210410 11:50:56.423243 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:50:57.124595 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 8.1s [applied=1, batches=1, state_assertions=0]
I210410 11:50:59.042415 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 11:51:00.923617 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500201412s; err=context deadline exceeded
W210410 11:51:00.923739 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:51:01.538618 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 10.4s [applied=1, batches=1, state_assertions=0]
W210410 11:51:03.668473 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 6.5s [applied=1, batches=1, state_assertions=0]
W210410 11:51:05.424051 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500216996s; err=context deadline exceeded
W210410 11:51:05.424313 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

I210410 11:51:06.086811 112 gossip/gossip.go:568 ⋮ [n1] gossip status (stalled, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:51:06.106253 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 98 MiB RSS, 236 goroutines, 24 MiB/28 MiB/53 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 0.9/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:51:07.795793 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 6.3s [applied=1, batches=1, state_assertions=0]
W210410 11:51:08.598754 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 4.9s [applied=1, batches=1, state_assertions=0]
W210410 11:51:09.553582 10716 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] slow range RPC: ‹have been waiting 60.00s (1 attempts) for RPC TruncateLog [/Table/28,/Min) to r24:/Table/2{8-9} [(n1,s1):1, next=2, gen=0]; resp: aborted during DistSender.Send: context deadline exceeded›
W210410 11:51:09.553652 11197 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] slow heartbeat took 22.131487948s; err=‹aborted during DistSender.Send: context canceled›
W210410 11:51:09.553758 10716 kv/kvclient/kvcoord/dist_sender.go:1507 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] slow RPC response: ‹slow RPC finished after 60.00s (1 attempts)›
E210410 11:51:09.553760 11197 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] ‹aborted during DistSender.Send: context canceled›
E210410 11:51:09.553864 10716 kv/kvserver/queue.go:1087 ⋮ [n1,raftlog,s1,r24/1:‹/Table/2{8-9}›] ‹operation "raftlog queue process replica 24" timed out after 1m0s›
W210410 11:51:09.924680 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500208773s; err=context deadline exceeded
W210410 11:51:09.924849 278 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 11:51:10.145723 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.3s [applied=1, batches=1, state_assertions=0]
W210410 11:51:10.871607 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.3s [applied=1, batches=1, state_assertions=0]
W210410 11:51:11.727535 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
I210410 11:51:12.479330 171 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 11:51:12.554089 11507 kv/txn.go:750 ⋮ [n1] async rollback failed: ‹context deadline exceeded›
W210410 11:51:12.677464 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
I210410 11:51:12.913416 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618055434.501060141,0 is behind by 38.412352106s
W210410 11:51:13.833281 11274 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 26.41093855s; err=<nil>
W210410 11:51:13.833379 11283 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] slow heartbeat took 26.411038331s; err=<nil>
W210410 11:51:13.833592 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:51:13.833909 11298 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] slow heartbeat took 26.411418342s; err=<nil>
W210410 11:51:13.834017 11259 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 26.411408503s; err=<nil>
W210410 11:51:13.834210 11057 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 26.41155793s; err=<nil>
W210410 11:51:13.834780 11198 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 26.41198729s; err=<nil>
W210410 11:51:13.834911 11200 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] slow heartbeat took 25.271918821s; err=<nil>
W210410 11:51:14.580884 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.655893398s; err=<nil>
W210410 11:51:14.580903 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.580943 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.580944 154 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.580910 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.581051 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.581078 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.581216 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.581470 9973 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,intExec=‹stmt-diag-poll›,txn=‹0f1d58ae›] slow range RPC: ‹have been waiting 160.49s (1 attempts) for RPC [txn: 0f1d58ae], [can-forward-ts], Get [/Table/3/1/35/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.581628 10266 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,txn=‹427a2d4b›] slow range RPC: ‹have been waiting 115.35s (1 attempts) for RPC [txn: 427a2d4b], [can-forward-ts], Get [/Table/3/1/57/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.581051 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:14.583356 9758 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [intExec=‹expire-sessions›,n1,txn=‹fe026f22›] slow range RPC: ‹have been waiting 160.31s (1 attempts) for RPC [txn: fe026f22], [can-forward-ts], Get [/Table/3/1/15/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.610792 10265 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,intExec=‹scheduler-stats›,txn=‹57d75279›] slow range RPC: ‹have been waiting 122.46s (1 attempts) for RPC [txn: 57d75279], [can-forward-ts], Get [/Table/3/1/37/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.610797 10189 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [intExec=‹protectedts-GetMetadata›,n1,txn=‹1fabc6ad›] slow range RPC: ‹have been waiting 120.58s (1 attempts) for RPC [txn: 1fabc6ad], [can-forward-ts], Get [/Table/3/1/31/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.610846 10411 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,txn=‹e1930f4e›] slow range RPC: ‹have been waiting 115.38s (1 attempts) for RPC [txn: e1930f4e], [can-forward-ts], Get [/Table/3/1/69/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:14.737819 9965 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [intExec=‹claim-jobs›,n1,txn=‹3571dc64›] slow range RPC: ‹have been waiting 154.29s (1 attempts) for RPC [txn: 3571dc64], [can-forward-ts], Get [/Table/3/1/15/2/1,/Min) to r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.GetResponse›
W210410 11:51:16.375749 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r101/1:‹/Table/72{-/2}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.375885 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.375945 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.376147 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.376240 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.375840 154 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.375997 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:16.376740 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
I210410 11:51:16.379528 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 98 MiB RSS, 225 goroutines, 28 MiB/25 MiB/53 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:51:17.065851 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:51:17.593425 149 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:51:17.593452 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 11:51:17.593614 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.2s [applied=2, batches=2, state_assertions=0]
W210410 11:51:17.600899 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.2s [applied=2, batches=2, state_assertions=0]
W210410 11:51:17.626190 277 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,ts-poll] slow range RPC: ‹have been waiting 168.33s (1 attempts) for RPC Merge [/System/tsd/cr.node.rpc.heartbeats.loops.started/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.rpc.heartbeats.loops.exited/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.rpc.heartbeats.initializing/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.rpc.heartbeats.nominal/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.rpc.heartbeats.failed/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.connections.incoming/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.connections.refused/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.bytes.received/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.bytes.sent/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.infos.received/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.infos.sent/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.gossip.connections.outgoing/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.cgocalls/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.goroutines/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.go.allocbytes/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.go.totalbytes/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.cgo.allocbytes/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.cgo.totalbytes/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.gc.count/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.node.sys.gc.pause.ns/1/10s/2021-04-10T11:00:00Z,/Min), ... 769 skipped ..., Merge [/System/tsd/cr.store.txnrecovery.successes.aborted/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.store.txnrecovery.successes.pending/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.store.txnrecovery.failures/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.store.rebalancing.lease.transfers/1/10s/2021-04-10T11:00:00Z,/Min), Merge [/System/tsd/cr.store.rebalancing.range.rebalances/1/10s/2021-04-10T11:00:00Z,/Min) to r4:/System{/tsd-tse} [(n1,s1):1, next=2, gen=0]; resp: (err: <nil>), *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, ... 769 skipped ..., *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse, *roachpb.MergeResponse›
W210410 11:51:17.997864 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.41692039s; err=<nil>
W210410 11:51:17.997947 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:17.998006 152 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=2, batches=2, state_assertions=0]
W210410 11:51:17.998103 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:51:18.422798 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:18.422791 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:18.423057 234 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:18.423168 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:51:18.424670 9789 kv/kvclient/kvcoord/dist_sender.go:1499 ⋮ [n1,intExec=‹delete-sessions›,txn=‹4b9480cf›] slow range RPC: ‹have been waiting 175.87s (1 attempts) for RPC [txn: 4b9480cf], Scan [/Table/39/1,/Table/39/2) to r35:/Table/{39-53} [(n1,s1):1, next=2, gen=1]; resp: (err: <nil>), *roachpb.ScanResponse›
W210410 11:51:18.733998 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:18.733934 11603 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r28/1:‹/Table/3{2-3}›] slow heartbeat took 4.152604345s; err=<nil>
W210410 11:51:18.734079 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.7s [applied=3, batches=1, state_assertions=0]
W210410 11:51:19.057582 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:51:19.057648 234 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:51:19.057737 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r23/1:‹/Table/2{7-8}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:51:19.060949 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:51:19.255855 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:51:19.255840 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:51:19.256112 156 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:51:20.055916 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.057985425s; err=<nil>
W210410 11:51:20.378887 11665 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r12/1:‹/Table/1{6-7}›] slow heartbeat took 1.119995494s; err=<nil>
W210410 11:51:22.020973 11763 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r19/1:‹/Table/2{3-4}›] slow heartbeat took 1.139632358s; err=<nil>
W210410 11:51:22.537128 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:22.884527 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.796908939s; err=<nil>
W210410 11:51:22.884976 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r19/1:‹/Table/2{3-4}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:51:24.151752 11809 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r20/1:‹/Table/2{4-5}›] slow heartbeat took 1.2615608s; err=<nil>
W210410 11:51:25.039024 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:51:25.039203 243 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:51:25.793682 11847 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r5/1:‹/{Systemtse-Table/System…}›] slow heartbeat took 1.184855984s; err=<nil>
I210410 11:51:26.109167 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 209 goroutines, 26 MiB/27 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 6.3/1.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:51:36.108845 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 206 goroutines, 33 MiB/22 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:51:46.109059 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 103 MiB RSS, 205 goroutines, 40 MiB/16 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:51:56.109458 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 206 goroutines, 24 MiB/28 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:52:06.087027 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
  n1 [sentinel];
I210410 11:52:06.109899 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 205 goroutines, 30 MiB/24 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:52:16.110061 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 206 goroutines, 37 MiB/18 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/1.0 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:52:26.109930 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 206 goroutines, 27 MiB/28 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.3/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:52:36.108308 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 206 goroutines, 33 MiB/23 MiB/57 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.2 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:52:46.108449 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 205 goroutines, 20 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:52:56.183530 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 205 goroutines, 27 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:53:06.086896 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:53:06.121513 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 205 goroutines, 33 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:53:10.171403 227 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:53:10.176561 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:53:10.403187 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.315532595s; err=<nil>
I210410 11:53:16.110963 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 206 goroutines, 23 MiB/30 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.8 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:53:26.111168 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 206 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.8 %(u/s)time, 0.0 %gc (0x), 87 B/0 B (r/w)net
W210410 11:53:32.180169 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:53:32.460375 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:53:32.819404 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:53:32.989244 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.401743455s; err=<nil>
W210410 11:53:32.989476 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
I210410 11:53:36.109785 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 101 MiB RSS, 206 goroutines, 37 MiB/19 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:53:46.112041 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 205 goroutines, 24 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.6 %(u/s)time, 0.0 %gc (1x), 214 B/0 B (r/w)net
I210410 11:53:56.112216 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 205 goroutines, 30 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:54:06.086992 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:54:06.112956 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 205 goroutines, 37 MiB/19 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:54:16.110541 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 102 MiB RSS, 206 goroutines, 26 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:54:26.112739 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 103 MiB RSS, 206 goroutines, 34 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:54:36.145136 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 103 MiB RSS, 206 goroutines, 23 MiB/30 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/0.9 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:54:46.113466 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 205 goroutines, 30 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.9 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:54:56.113986 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 205 goroutines, 36 MiB/20 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:55:06.087098 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:55:06.113670 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 205 goroutines, 24 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.6 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:55:16.114353 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 104 MiB RSS, 206 goroutines, 30 MiB/25 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:55:26.114202 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 208 goroutines, 20 MiB/31 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 4.7/0.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:55:36.114482 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 206 goroutines, 26 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.4 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:55:37.771437 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:55:38.040310 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:55:38.285581 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:55:38.642049 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:55:39.521256 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:55:40.489919 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.902226797s; err=<nil>
W210410 11:55:43.028459 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:55:44.297999 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.3s [applied=2, batches=1, state_assertions=0]
W210410 11:55:44.889497 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:55:44.889806 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:55:45.111619 160 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:55:45.189956 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.102302221s; err=<nil>
I210410 11:55:46.115144 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 105 MiB RSS, 205 goroutines, 33 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:55:56.115054 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 106 MiB RSS, 205 goroutines, 22 MiB/31 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/0.8 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:56:06.087049 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:56:06.119514 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 205 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.6 %(u/s)time, 0.0 %gc (0x), 70 B/0 B (r/w)net
I210410 11:56:16.115621 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 206 goroutines, 34 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:56:26.115874 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 206 goroutines, 25 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.3/0.8 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:56:36.116135 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 206 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:56:46.116246 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 108 MiB RSS, 205 goroutines, 38 MiB/19 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:56:56.116943 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 108 MiB RSS, 205 goroutines, 25 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:57:06.087102 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:57:06.117673 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 108 MiB RSS, 206 goroutines, 31 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:57:16.117196 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 109 MiB RSS, 206 goroutines, 20 MiB/32 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/0.7 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 11:57:26.129595 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 110 MiB RSS, 206 goroutines, 28 MiB/27 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/0.9 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:57:26.090235 111 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 787K 1 ]: 787K›
I210410 11:57:26.159124 111 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2    27 M       -    27 M       -       -       -       -    27 M       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   787 K       -   325 K     0 B       0     0 B       0   787 K       1   938 K       1     2.4›
‹  total         1   787 K       -    27 M     0 B       0     0 B       0    28 M       1   938 K       1     1.0›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2    64 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        35   1.1 M   99.4%  (score == hit-rate)›
‹ tcache         1   616 B  100.0%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   72.6%  (score == utility)›
I210410 11:57:36.117528 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 110 MiB RSS, 206 goroutines, 35 MiB/22 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 11:57:46.117736 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 110 MiB RSS, 205 goroutines, 24 MiB/29 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/0.7 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
W210410 11:57:48.671159 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:57:51.159587 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 3.3s [applied=1, batches=1, state_assertions=0]
W210410 11:57:51.299471 246 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.6s [applied=1, batches=1, state_assertions=0]
W210410 11:57:51.299538 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
W210410 11:57:51.301839 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:57:51.667254 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.579670515s; err=<nil>
I210410 11:57:56.118149 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 110 MiB RSS, 205 goroutines, 30 MiB/24 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.6 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:57:58.811874 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=2, batches=2, state_assertions=0]
W210410 11:57:59.981781 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.894199885s; err=<nil>
W210410 11:57:59.981991 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.259433 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.259632 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.266229 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.482976 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 11:58:00.917293 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.917309 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:58:00.917308 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:58:01.284176 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 11:58:01.607265 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:58:01.962680 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:58:02.678230 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.090626578s; err=<nil>
I210410 11:58:06.087009 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:58:06.118148 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 108 MiB RSS, 205 goroutines, 37 MiB/19 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/0.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 11:58:11.139832 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:58:11.673870 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.086326836s; err=<nil>
I210410 11:58:16.116817 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 112 MiB RSS, 206 goroutines, 28 MiB/26 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.6 %(u/s)time, 0.0 %gc (1x), 2.1 KiB/11 KiB (r/w)net
I210410 11:58:26.118582 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 112 MiB RSS, 207 goroutines, 36 MiB/20 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.1 %(u/s)time, 0.0 %gc (0x), 84 B/0 B (r/w)net
W210410 11:58:29.621070 232 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:58:36.185274 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 112 MiB RSS, 206 goroutines, 25 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/0.7 %(u/s)time, 0.0 %gc (1x), 2.2 KiB/11 KiB (r/w)net
W210410 11:58:41.489560 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 11:58:41.778523 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 11:58:42.012421 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:58:43.681158 150 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:58:44.037067 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.949366469s; err=<nil>
I210410 11:58:46.119667 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 205 goroutines, 35 MiB/21 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/0.7 %(u/s)time, 0.0 %gc (0x), 2.1 KiB/11 KiB (r/w)net
W210410 11:58:47.869174 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.281576779s; err=<nil>
W210410 11:58:50.221049 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:58:50.498500 245 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:58:54.659363 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:58:56.119245 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 107 MiB RSS, 205 goroutines, 26 MiB/28 MiB/54 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.5/0.6 %(u/s)time, 0.0 %gc (1x), 2.1 KiB/11 KiB (r/w)net
I210410 11:59:03.323505 17536 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r40/1:‹/Table/54{-/2}›] initiating a merge of r41:‹/Table/54/{2-3}› [(n1,s1):1, next=2, gen=7, sticky=1618055936.611040256,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:05.045900 253 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r40/1:‹/Table/54{-/2}›] removing replica r41/1
W210410 11:59:05.192943 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r40/1:‹/Table/54{-/3}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=1]
I210410 11:59:06.087081 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 11:59:06.169965 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 115 MiB RSS, 217 goroutines, 23 MiB/29 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.7 CGO/sec, 6.4/0.9 %(u/s)time, 0.0 %gc (1x), 6.3 KiB/24 KiB (r/w)net
W210410 11:59:06.166912 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:59:06.660226 148 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 11:59:06.849242 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r40/1:‹/Table/54{-/3}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:59:06.849241 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:59:09.196007 17839 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r40/1:‹/Table/54{-/3}›] initiating a merge of r42:‹/Table/5{4/3-5}› [(n1,s1):1, next=2, gen=8, sticky=1618055939.067611429,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:09.926788 238 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r40/1:‹/Table/54{-/3}›] removing replica r42/1
I210410 11:59:10.196492 17862 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r38/1:‹/Table/53/{3-4}›] initiating a merge of r39:‹/Table/5{3/4-4}› [(n1,s1):1, next=2, gen=5, sticky=1618055934.343288779,0] into this range (‹lhs+rhs has (size=66 B+48 B=114 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
W210410 11:59:11.188519 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:59:11.188573 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r39/1:‹/Table/5{3/4-4}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 11:59:11.706638 235 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r38/1:‹/Table/53/{3-4}›] removing replica r39/1
I210410 11:59:16.119951 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 116 MiB RSS, 215 goroutines, 38 MiB/18 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.0 %(u/s)time, 0.0 %gc (0x), 7.1 KiB/24 KiB (r/w)net
I210410 11:59:17.762075 17971 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r49/1:‹/Table/57/{2-3}›] initiating a merge of r50:‹/Table/5{7/3-8}› [(n1,s1):1, next=2, gen=16, sticky=1618055953.348472920,0] into this range (‹lhs+rhs has (size=41 B+50 B=91 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:18.227405 248 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r49/1:‹/Table/57/{2-3}›] removing replica r50/1
W210410 11:59:19.897690 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r49/1:‹/Table/5{7/2-8}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:59:20.388280 159 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 11:59:20.645045 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r49/1:‹/Table/5{7/2-8}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 11:59:20.645043 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 11:59:20.762527 17996 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r48/1:‹/Table/57{-/2}›] initiating a merge of r49:‹/Table/5{7/2-8}› [(n1,s1):1, next=2, gen=17, sticky=1618055950.533960179,0] into this range (‹lhs+rhs has (size=289 B+91 B=380 B qps=0.00+0.71=0.71qps) below threshold (size=128 MiB, qps=1250.00)›)
W210410 11:59:21.792752 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r9/1:‹/Table/1{3-4}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 11:59:22.127131 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:59:22.684283 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 11:59:22.684443 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 11:59:23.598180 235 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r49/1:‹/Table/5{7/2-8}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:59:23.598266 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.3s [applied=2, batches=2, state_assertions=0]
W210410 11:59:24.322569 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:59:24.322596 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 11:59:25.326136 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 11:59:25.638271 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:59:25.638357 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 11:59:25.749336 278 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.161732189s; err=<nil>
I210410 11:59:25.872200 214 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r48/1:‹/Table/57{-/2}›] removing replica r49/1
I210410 11:59:26.124723 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 117 MiB RSS, 217 goroutines, 31 MiB/23 MiB/55 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.6 %(u/s)time, 0.0 %gc (1x), 5.2 KiB/13 KiB (r/w)net
W210410 11:59:32.558248 158 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r9/1:‹/Table/1{3-4}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 11:59:36.120467 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 118 MiB RSS, 215 goroutines, 42 MiB/15 MiB/56 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/1.0 %(u/s)time, 0.0 %gc (0x), 4.7 KiB/12 KiB (r/w)net
I210410 11:59:46.120457 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 127 MiB RSS, 214 goroutines, 34 MiB/20 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.7/0.8 %(u/s)time, 0.0 %gc (1x), 4.5 KiB/13 KiB (r/w)net
I210410 11:59:55.773756 18462 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r46/1:‹/Table/56{-/2}›] initiating a merge of r47:‹/Table/5{6/2-7}› [(n1,s1):1, next=2, gen=13, sticky=1618055947.832178968,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:56.120762 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 128 MiB RSS, 219 goroutines, 41 MiB/15 MiB/58 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/0.8 %(u/s)time, 0.0 %gc (0x), 2.2 KiB/2.1 KiB (r/w)net
I210410 11:59:56.194074 232 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r46/1:‹/Table/56{-/2}›] removing replica r47/1
I210410 11:59:56.774075 18489 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r43/1:‹/Table/55{-/2}›] initiating a merge of r44:‹/Table/55/{2-3}› [(n1,s1):1, next=2, gen=10, sticky=1618055942.496430013,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:57.031387 157 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r43/1:‹/Table/55{-/2}›] removing replica r44/1
I210410 11:59:57.034154 18541 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r43/1:‹/Table/55{-/3}›] initiating a merge of r45:‹/Table/5{5/3-6}› [(n1,s1):1, next=2, gen=11, sticky=1618055945.319777918,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:57.452154 257 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r43/1:‹/Table/55{-/3}›] removing replica r45/1
I210410 11:59:58.776000 18596 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r53/1:‹/Table/59{-/2}›] initiating a merge of r54:‹/Table/59/{2-3}› [(n1,s1):1, next=2, gen=20, sticky=1618055959.144465586,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:59.238675 161 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r53/1:‹/Table/59{-/2}›] removing replica r54/1
I210410 11:59:59.241255 18581 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r53/1:‹/Table/59{-/3}›] initiating a merge of r55:‹/Table/{59/3-60}› [(n1,s1):1, next=2, gen=21, sticky=1618055961.891647193,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 11:59:59.751739 152 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r53/1:‹/Table/59{-/3}›] removing replica r55/1
I210410 12:00:00.775245 18497 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r68/1:‹/Table/62/{3-4}›] initiating a merge of r69:‹/Table/6{2/4-3}› [(n1,s1):1, next=2, gen=35, sticky=1618055992.418376470,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:01.046219 238 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r68/1:‹/Table/62/{3-4}›] removing replica r69/1
I210410 12:00:04.778103 18649 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r51/1:‹/Table/58{-/2}›] initiating a merge of r52:‹/Table/5{8/2-9}› [(n1,s1):1, next=2, gen=18, sticky=1618055956.285797186,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:05.184914 157 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r51/1:‹/Table/58{-/2}›] removing replica r52/1
I210410 12:00:06.087008 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 12:00:06.121402 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 131 MiB RSS, 215 goroutines, 29 MiB/24 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 4.1/1.0 %(u/s)time, 0.3 %gc (1x), 4.9 KiB/4.9 KiB (r/w)net
I210410 12:00:08.780188 18789 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r60/1:‹/Table/60/{5-6}›] initiating a merge of r61:‹/Table/60/{6-7}› [(n1,s1):1, next=2, gen=27, sticky=1618055973.986367491,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:09.102541 150 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r60/1:‹/Table/60/{5-6}›] removing replica r61/1
I210410 12:00:09.105659 18811 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r60/1:‹/Table/60/{5-7}›] initiating a merge of r62:‹/Table/6{0/7-1}› [(n1,s1):1, next=2, gen=28, sticky=1618055976.888729473,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:09.939787 228 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r60/1:‹/Table/60/{5-7}›] removing replica r62/1
W210410 12:00:10.982125 221 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r60/1:‹/Table/6{0/5-1}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 12:00:16.176685 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 131 MiB RSS, 216 goroutines, 39 MiB/16 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.7 %(u/s)time, 0.0 %gc (0x), 5.3 KiB/14 KiB (r/w)net
I210410 12:00:20.783832 18864 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r58/1:‹/Table/60/{3-4}›] initiating a merge of r59:‹/Table/60/{4-5}› [(n1,s1):1, next=2, gen=25, sticky=1618055969.338627082,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:21.714343 151 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r58/1:‹/Table/60/{3-4}›] removing replica r59/1
I210410 12:00:21.715449 19043 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r58/1:‹/Table/60/{3-5}›] initiating a merge of r60:‹/Table/6{0/5-1}› [(n1,s1):1, next=2, gen=29, sticky=1618055971.629774826,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:22.375617 235 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r58/1:‹/Table/60/{3-5}›] removing replica r60/1
I210410 12:00:22.379081 19045 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r63/1:‹/Table/61{-/2}›] initiating a merge of r64:‹/Table/61/{2-3}› [(n1,s1):1, next=2, gen=30, sticky=1618055979.425106935,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:22.710713 211 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r63/1:‹/Table/61{-/2}›] removing replica r64/1
I210410 12:00:22.713781 18767 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r63/1:‹/Table/61{-/3}›] initiating a merge of r65:‹/Table/6{1/3-2}› [(n1,s1):1, next=2, gen=31, sticky=1618055982.843822060,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:23.112843 251 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r63/1:‹/Table/61{-/3}›] removing replica r65/1
I210410 12:00:23.115849 18923 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r74/1:‹/Table/64{-/2}›] initiating a merge of r75:‹/Table/64/{2-3}› [(n1,s1):1, next=2, gen=40, sticky=1618055999.944125613,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:23.492428 229 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r74/1:‹/Table/64{-/2}›] removing replica r75/1
I210410 12:00:23.495407 19068 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r74/1:‹/Table/64{-/3}›] initiating a merge of r76:‹/Table/6{4/3-5}› [(n1,s1):1, next=2, gen=41, sticky=1618056003.015077016,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:24.072507 233 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r74/1:‹/Table/64{-/3}›] removing replica r76/1
I210410 12:00:24.076349 19079 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r67/1:‹/Table/62/{2-3}›] initiating a merge of r68:‹/Table/6{2/3-3}› [(n1,s1):1, next=2, gen=36, sticky=1618055989.391309039,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:24.476522 223 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r67/1:‹/Table/62/{2-3}›] removing replica r68/1
I210410 12:00:26.121325 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 132 MiB RSS, 215 goroutines, 29 MiB/24 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 4.5/1.1 %(u/s)time, 0.0 %gc (1x), 7.7 KiB/5.6 KiB (r/w)net
I210410 12:00:26.785465 19188 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r56/1:‹/Table/60{-/2}›] initiating a merge of r57:‹/Table/60/{2-3}› [(n1,s1):1, next=2, gen=23, sticky=1618055964.170324726,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:27.204062 248 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r56/1:‹/Table/60{-/2}›] removing replica r57/1
I210410 12:00:27.206817 19206 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r56/1:‹/Table/60{-/3}›] initiating a merge of r58:‹/Table/6{0/3-1}› [(n1,s1):1, next=2, gen=30, sticky=1618055967.016258444,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:27.650543 245 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r56/1:‹/Table/60{-/3}›] removing replica r58/1
I210410 12:00:34.788328 19315 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r87/1:‹/Table/69{-/2}›] initiating a merge of r88:‹/Table/69/{2-3}› [(n1,s1):1, next=2, gen=53, sticky=1618056022.111293625,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:35.060911 238 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r87/1:‹/Table/69{-/2}›] removing replica r88/1
I210410 12:00:35.064312 19363 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r87/1:‹/Table/69{-/3}›] initiating a merge of r89:‹/Table/69/{3-4}› [(n1,s1):1, next=2, gen=54, sticky=1618056024.958141864,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:35.458942 160 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r87/1:‹/Table/69{-/3}›] removing replica r89/1
I210410 12:00:36.121613 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 132 MiB RSS, 217 goroutines, 38 MiB/18 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/0.9 %(u/s)time, 0.0 %gc (0x), 4.2 KiB/3.7 KiB (r/w)net
W210410 12:00:36.987152 161 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r87/1:‹/Table/69{-/4}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 12:00:37.032063 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 12:00:37.789259 19399 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r72/1:‹/Table/63/{2-3}›] initiating a merge of r73:‹/Table/6{3/3-4}› [(n1,s1):1, next=2, gen=38, sticky=1618055997.476733193,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:38.091303 236 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r72/1:‹/Table/63/{2-3}›] removing replica r73/1
I210410 12:00:39.790628 19340 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r92/1:‹/Table/70{-/2}›] initiating a merge of r93:‹/Table/70/{2-3}› [(n1,s1):1, next=2, gen=58, sticky=1618056032.908179221,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:40.096720 213 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r92/1:‹/Table/70{-/2}›] removing replica r93/1
I210410 12:00:40.103845 19286 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r92/1:‹/Table/70{-/3}›] initiating a merge of r94:‹/Table/70/{3-4}› [(n1,s1):1, next=2, gen=59, sticky=1618056036.010511632,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:40.443272 229 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r92/1:‹/Table/70{-/3}›] removing replica r94/1
I210410 12:00:40.790482 19449 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r90/1:‹/Table/69/{4-5}›] initiating a merge of r91:‹/Table/{69/5-70}› [(n1,s1):1, next=2, gen=56, sticky=1618056030.216264220,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:41.122986 215 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r90/1:‹/Table/69/{4-5}›] removing replica r91/1
I210410 12:00:43.791959 19570 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r70/1:‹/Table/63{-/2}›] initiating a merge of r72:‹/Table/6{3/2-4}› [(n1,s1):1, next=2, gen=39, sticky=1618055994.863493722,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:44.084657 148 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r70/1:‹/Table/63{-/2}›] removing replica r72/1
I210410 12:00:45.791180 19543 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r36/1:‹/Table/53{-/2}›] initiating a merge of r37:‹/Table/53/{2-3}› [(n1,s1):1, next=2, gen=3, sticky=1618055928.025102260,0] into this range (‹lhs+rhs has (size=92 B+41 B=133 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:46.066229 247 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r36/1:‹/Table/53{-/2}›] removing replica r37/1
I210410 12:00:46.069195 19619 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r36/1:‹/Table/53{-/3}›] initiating a merge of r38:‹/Table/5{3/3-4}› [(n1,s1):1, next=2, gen=6, sticky=1618055931.942948342,0] into this range (‹lhs+rhs has (size=133 B+114 B=247 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:46.121704 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 132 MiB RSS, 219 goroutines, 25 MiB/27 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 4.4/1.5 %(u/s)time, 0.0 %gc (1x), 5.5 KiB/5.5 KiB (r/w)net
I210410 12:00:46.492212 153 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r36/1:‹/Table/53{-/3}›] removing replica r38/1
I210410 12:00:47.792905 19625 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r80/1:‹/Table/66/{2-3}›] initiating a merge of r81:‹/Table/6{6/3-7}› [(n1,s1):1, next=2, gen=46, sticky=1618056011.110241064,0] into this range (‹lhs+rhs has (size=59 B+68 B=127 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:48.118396 217 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r80/1:‹/Table/66/{2-3}›] removing replica r81/1
I210410 12:00:49.794171 19680 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r95/1:‹/Table/70/{4-5}›] initiating a merge of r96:‹/Table/70/{5-6}› [(n1,s1):1, next=2, gen=61, sticky=1618056041.480218285,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:50.067207 211 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r95/1:‹/Table/70/{4-5}›] removing replica r96/1
I210410 12:00:50.070008 19659 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r95/1:‹/Table/70/{4-6}›] initiating a merge of r97:‹/Table/7{0/6-1}› [(n1,s1):1, next=2, gen=62, sticky=1618056044.808654805,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:50.402501 245 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r95/1:‹/Table/70/{4-6}›] removing replica r97/1
I210410 12:00:51.793762 19746 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r84/1:‹/Table/68{-/2}›] initiating a merge of r85:‹/Table/68/{2-3}› [(n1,s1):1, next=2, gen=50, sticky=1618056016.815175700,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:52.085382 237 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r84/1:‹/Table/68{-/2}›] removing replica r85/1
I210410 12:00:52.088048 19764 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r84/1:‹/Table/68{-/3}›] initiating a merge of r86:‹/Table/6{8/3-9}› [(n1,s1):1, next=2, gen=51, sticky=1618056019.440038897,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:00:52.576273 234 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r84/1:‹/Table/68{-/3}›] removing replica r86/1
I210410 12:00:56.122401 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 133 MiB RSS, 214 goroutines, 34 MiB/21 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.1/1.1 %(u/s)time, 0.0 %gc (0x), 4.9 KiB/4.4 KiB (r/w)net
I210410 12:01:00.797276 19830 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r66/1:‹/Table/62{-/2}›] initiating a merge of r67:‹/Table/6{2/2-3}› [(n1,s1):1, next=2, gen=37, sticky=1618055986.328136321,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:01:01.073320 157 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r66/1:‹/Table/62{-/2}›] removing replica r67/1
I210410 12:01:03.796988 19921 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r79/1:‹/Table/66{-/2}›] initiating a merge of r80:‹/Table/6{6/2-7}› [(n1,s1):1, next=2, gen=47, sticky=1618056008.508787398,0] into this range (‹lhs+rhs has (size=110 B+127 B=237 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:01:04.070003 248 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r79/1:‹/Table/66{-/2}›] removing replica r80/1
I210410 12:01:06.086906 112 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 12:01:06.123729 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 133 MiB RSS, 214 goroutines, 41 MiB/16 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/0.9 %(u/s)time, 0.0 %gc (0x), 2.7 KiB/2.7 KiB (r/w)net
I210410 12:01:08.798696 19902 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r104/1:‹/Table/73/{3-4}›] initiating a merge of r105:‹/Table/7{3/4-4}› [(n1,s1):1, next=2, gen=69, sticky=1618056060.510550124,0] into this range (‹lhs+rhs has (size=41 B+57 B=98 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
W210410 12:01:10.035830 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 12:01:10.242681 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 12:01:10.242806 157 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r104/1:‹/Table/73/{3-4}›] removing replica r105/1
W210410 12:01:10.243500 157 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r104/1:‹/Table/7{3/3-4}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=1]
I210410 12:01:12.800451 19773 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r82/1:‹/Table/67{-/2}›] initiating a merge of r83:‹/Table/6{7/2-8}› [(n1,s1):1, next=2, gen=48, sticky=1618056013.957727227,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:01:13.440558 258 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r82/1:‹/Table/67{-/2}›] removing replica r83/1
I210410 12:01:15.802445 20147 kv/kvserver/replica_command.go:671 ⋮ [n1,merge,s1,r77/1:‹/Table/65{-/2}›] initiating a merge of r78:‹/Table/6{5/2-6}› [(n1,s1):1, next=2, gen=43, sticky=1618056005.460687782,0] into this range (‹lhs+rhs has (size=0 B+0 B=0 B qps=0.00+0.00=0.00qps) below threshold (size=128 MiB, qps=1250.00)›)
I210410 12:01:16.090150 156 kv/kvserver/store_remove_replica.go:127 ⋮ [n1,s1,r77/1:‹/Table/65{-/2}›] removing replica r78/1
I210410 12:01:16.122442 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 133 MiB RSS, 218 goroutines, 31 MiB/22 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 3.8/0.8 %(u/s)time, 0.0 %gc (1x), 5.5 KiB/14 KiB (r/w)net
I210410 12:01:26.122553 276 server/status/runtime.go:525 ⋮ [n1] runtime stats: 134 MiB RSS, 215 goroutines, 38 MiB/17 MiB/59 MiB GO alloc/idle/total, 74 MiB/81 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.7 %(u/s)time, 0.0 %gc (0x), 2.1 KiB/1.6 KiB (r/w)net
I210410 12:01:28.049604 1 cli/start.go:736 ⋮ received signal 'terminated'
I210410 12:01:28.087829 1 cli/start.go:821 ⋮ initiating graceful shutdown of server
I210410 12:01:28.953089 20346 server/drain.go:174 ⋮ [server drain process] drain remaining: 4
I210410 12:01:28.953194 20346 server/drain.go:176 ⋮ [server drain process] drain details: descriptor leases: 3, liveness record: 1
W210410 12:01:29.867486 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 12:01:30.017947 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 12:01:30.024039 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 12:01:30.083971 20346 server/drain.go:174 ⋮ [server drain process] drain remaining: 0
I210410 12:01:30.084116 20346 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W210410 12:01:30.084261 568 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
W210410 12:01:30.084440 579 jobs/registry.go:675 ⋮ canceling all adopted jobs due to stopper quiescing
I210410 12:01:30.255950 256 kv/kvserver/queue.go:582 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] rate limited in MaybeAdd (merge): ‹node unavailable; try another peer›
E210410 12:01:30.312727 20430 kv/kvserver/queue.go:1087 ⋮ [n1,raftlog,s1,r4/1:‹/System{/tsd-tse}›] ‹result is ambiguous (server shutdown)›
I210410 12:01:31.129683 1 cli/start.go:873 ⋮ server drained and shutdown completed
