I210410 16:08:58.099005 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/10 16:08:58
I210410 16:08:58.099046 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹755e1052c718›
I210410 16:08:58.099085 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)
I210410 16:08:58.099118 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start-single-node --http-port 26256 --insecure]›
I210410 16:08:58.099167 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W210410 16:08:58.098596 1 cli/start.go:1143 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I210410 16:08:58.099569 1 cli/start.go:1153 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I210410 16:08:58.100891 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
W210410 16:08:58.100976 1 cli/start.go:987 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (1.9 GiB).›
I210410 16:08:58.101791 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 16:08:58.101834 1 cli/start.go:1168 ⋮ ‹CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)›
I210410 16:08:58.595412 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 16:08:58.595488 1 server/config.go:428 ⋮ system total memory: ‹7.6 GiB›
I210410 16:08:58.608678 1 server/config.go:430 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   1.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210410 16:08:58.608903 1 cli/start.go:965 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I210410 16:08:58.608994 1 cli/start.go:972 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I210410 16:09:00.089970 1 cli/start.go:511 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I210410 16:09:00.090089 1 cli/start.go:516 ⋮ starting cockroach node
I210410 16:09:05.686902 39 server/server.go:790 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210410 16:09:08.478170 39 server/config.go:619 ⋮ [n?] 1 storage engine‹› initialized
I210410 16:09:08.509897 39 server/config.go:622 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I210410 16:09:08.509942 39 server/config.go:622 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
W210410 16:09:09.244625 39 cli/start.go:911 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"755e1052c718"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I210410 16:09:09.244956 181 server/server.go:1424 ⋮ [n1] connecting to gossip network to verify cluster ID ‹"dd9dc586-c756-4f4b-a9e5-9e23cf559418"›
I210410 16:09:09.244873 39 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"755e1052c718:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.7" started_at:1618070949244858039 cluster_name:"" sql_address:<network_field:"tcp" address_field:"755e1052c718:26257" >›
W210410 16:09:10.081678 253 kv/kvserver/replica_range_lease.go:556 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 16:09:10.083111 253 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 16:09:10.083921 181 server/server.go:1427 ⋮ [n1] node connected via gossip
W210410 16:09:10.568254 253 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 16:09:10.668479 253 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 16:09:10.791810 39 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=196 GiB, available=4.3 GiB, used=6.7 MiB, logicalBytes=31 MiB), ranges=57, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=333.00 p90=52763.00 pMax=31658220.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
W210410 16:09:10.889669 253 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 16:09:11.005922 39 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
W210410 16:09:11.299378 253 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 16:09:11.976918 60 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.4s [applied=3, batches=2, state_assertions=0]
W210410 16:09:11.977351 56 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.4s [applied=3, batches=2, state_assertions=0]
I210410 16:09:12.422926 39 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210410 16:09:12.423148 39 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
W210410 16:09:12.423081 57 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r5/1:‹/{Systemtse-Table/System…}›] handle raft ready: 1.5s [applied=2, batches=1, state_assertions=0]
I210410 16:09:12.423409 39 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I210410 16:09:12.423528 39 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210410 16:09:12.423641 39 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210410 16:09:12.423679 39 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210410 16:09:12.423769 39 server/server.go:1544 ⋮ [n1] starting http server at ‹[::]:26256› (use: ‹755e1052c718:26256›)
I210410 16:09:12.423915 39 server/server.go:1551 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210410 16:09:12.423999 39 server/server.go:1552 ⋮ [n1] advertising CockroachDB node at ‹755e1052c718:26257›
W210410 16:09:13.048673 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
I210410 16:09:13.146234 184 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 16:09:13.361640 184 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
W210410 16:09:13.629703 295 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 1.430014773s; err=<nil>
W210410 16:09:13.796867 267 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.372519404s; err=heartbeat failed on epoch increment
I210410 16:09:13.797143 267 kv/kvserver/node_liveness.go:640 ⋮ [n1,liveness-hb] heartbeat failed on epoch increment; retrying
W210410 16:09:14.318418 188 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 1.879853457s; err=<nil>
W210410 16:09:14.662736 289 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 2.152550536s; err=<nil>
W210410 16:09:14.854706 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 16:09:15.219479 39 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I210410 16:09:15.351682 39 server/server_sql.go:800 ⋮ [n1] done ensuring all necessary migrations have run
I210410 16:09:15.351810 39 server/server.go:1887 ⋮ [n1] serving sql connections
I210410 16:09:15.352199 39 cli/start.go:677 ⋮ [config] clusterID: ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
I210410 16:09:15.352321 39 cli/start.go:687 ⋮ node startup completed:
CockroachDB node starting at 2021-04-10 16:09:15.351970401 +0000 UTC (took 17.6s)
build:               CCL v20.2.7 @ 2021/03/29 17:52:00 (go1.13.14)
webui:               ‹http://755e1052c718:26256›
sql:                 ‹postgresql://root@755e1052c718:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=755e1052c718:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp247914781›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
nodeID:              1
I210410 16:09:15.455493 479 sql/temporary_schema.go:510 ⋮ [n1] running temporary object cleanup background job
I210410 16:09:15.457426 312 jobs/job_scheduler.go:349 ⋮ [n1] waiting 2m0s before scheduled jobs daemon start
W210410 16:09:15.574769 58 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:15.906530 267 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.062092671s; err=<nil>
W210410 16:09:15.906704 340 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r102/1:‹/Table/7{3-4}›] slow heartbeat took 1.587278765s; err=<nil>
W210410 16:09:16.637617 241 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 16:09:16.637676 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:09:16.637842 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] handle raft ready: 1.2s [applied=3, batches=2, state_assertions=0]
W210410 16:09:16.637902 58 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=2, batches=2, state_assertions=0]
W210410 16:09:16.638626 56 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:17.180450 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:09:17.180515 56 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:09:17.180506 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r102/1:‹/Table/7{3-4}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 16:09:17.180587 205 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r40/1:‹/Table/5{4-5}›] handle raft ready: 1.3s [applied=2, batches=1, state_assertions=0]
W210410 16:09:17.481949 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r63/1:‹/Table/6{1-2}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 16:09:17.761542 57 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:18.004377 118 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 1.63325842s; err=<nil>
W210410 16:09:18.515924 57 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:09:20.452102 335 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] slow heartbeat took 3.814020489s; err=<nil>
W210410 16:09:20.453776 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 16:09:20.719719 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r29/1:‹/Table/3{3-4}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 16:09:20.719926 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] handle raft ready: 1.8s [applied=2, batches=1, state_assertions=0]
W210410 16:09:21.553580 267 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.6289861s; err=<nil>
W210410 16:09:21.553919 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:09:21.554281 58 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
I210410 16:09:21.699243 479 sql/temporary_schema.go:545 ⋮ [n1] found 0 temporary schemas
I210410 16:09:21.699356 479 sql/temporary_schema.go:548 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I210410 16:09:21.699398 479 sql/temporary_schema.go:549 ⋮ [n1] completed temporary object cleanup job
I210410 16:09:21.699434 479 sql/temporary_schema.go:627 ⋮ [n1] temporary object cleaner next scheduled to run at 2021-04-10 16:39:15.303792501 +0000 UTC
W210410 16:09:21.765943 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:21.766047 60 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r27/1:‹/{NamespaceTab…-Table/32}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 16:09:21.766158 201 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 16:09:21.766047 56 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 16:09:21.766052 242 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r46/1:‹/Table/5{6-7}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
I210410 16:09:22.428349 265 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 229 goroutines, 23 MiB/97 MiB/65 MiB GO alloc/idle/total, 13 MiB/23 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (13x), 11 KiB/5.0 KiB (r/w)net
W210410 16:09:22.511056 508 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r102/1:‹/Table/7{3-4}›] slow heartbeat took 5.330401022s; err=<nil>
W210410 16:09:22.911889 61 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 16:09:22.911877 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:09:22.911874 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r98/1:‹/Table/7{1-2}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
W210410 16:09:22.912000 202 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=3, batches=1, state_assertions=0]
W210410 16:09:23.256860 272 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 6.07585611s; err=<nil>
W210410 16:09:23.257237 218 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r102/1:‹/Table/7{3-4}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.403931 535 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] slow heartbeat took 3.419121675s; err=<nil>
W210410 16:09:24.403992 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r9/1:‹/Table/1{3-4}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W210410 16:09:24.403999 565 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r27/1:‹/{NamespaceTab…-Table/32}›] slow heartbeat took 3.419189993s; err=<nil>
W210410 16:09:24.404046 511 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] slow heartbeat took 3.419237624s; err=<nil>
W210410 16:09:24.404091 234 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
W210410 16:09:24.404138 267 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.850420708s; err=<nil>
W210410 16:09:24.404165 661 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 2.709947328s; err=<nil>
W210410 16:09:24.404264 561 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] slow heartbeat took 2.705439978s; err=<nil>
W210410 16:09:24.404335 599 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 2.704963331s; err=<nil>
W210410 16:09:24.960901 61 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.960900 58 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.961116 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r27/1:‹/{NamespaceTab…-Table/32}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.960901 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.960921 194 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:24.961465 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 16:09:24.961653 313 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
W210410 16:09:25.875476 194 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:09:25.875516 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 16:09:25.875537 196 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
I210410 16:09:25.875996 686 sql/catalog/lease/lease.go:2124 ⋮ released orphaned lease: ‹{id:52 version:1 expiration:{Time:{wall:255936000 ext:63753666873 loc:<nil>}}}›
W210410 16:09:26.309329 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:26.931537 196 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:09:26.931600 194 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:09:26.931738 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:09:27.476483 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:09:27.480236 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I210410 16:09:27.866431 477 sql/sqlliveness/slstorage/slstorage.go:348 ⋮ [n1] inserted sqlliveness session ‹d6d5a4ac677c4dbc9af41a5da8b2f787›
I210410 16:09:27.866383 475 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:755e1052c718:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.7 StartedAt:1618070949244858039 LocalityAddress:[] ClusterName: SQLAddress:755e1052c718:26257} ClusterID:dd9dc586-c756-4f4b-a9e5-9e23cf559418 StartedAt:1618070949244858039 LastUp:1618069835364916346}›
W210410 16:09:27.866391 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:09:27.866404 194 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:09:27.866767 205 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
I210410 16:09:27.866481 477 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹d6d5a4ac677c4dbc9af41a5da8b2f787›
W210410 16:09:28.289630 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.289699 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.612048 267 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.687477482s; err=<nil>
W210410 16:09:28.612290 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.612314 205 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.612394 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.612426 61 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r87/1:‹/Table/{69-70}›] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
W210410 16:09:28.912887 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.912882 229 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:28.913117 195 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:29.180090 212 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:29.180090 204 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:29.840916 775 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r11/1:‹/Table/1{5-6}›] slow heartbeat took 1.646565451s; err=<nil>
I210410 16:09:32.427769 265 server/status/runtime.go:525 ⋮ [n1] runtime stats: 162 MiB RSS, 206 goroutines, 21 MiB/98 MiB/46 MiB GO alloc/idle/total, 14 MiB/24 MiB CGO alloc/total, 16.2 CGO/sec, 4.6/2.5 %(u/s)time, 0.0 %gc (1x), 8.7 KiB/21 KiB (r/w)net
I210410 16:09:32.427857 260 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 1M 1 ]: 1M›
I210410 16:09:32.428266 260 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2   529 K       -   526 K       -       -       -       -   529 K       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   1.3 M       -   112 K     0 B       0     0 B       0   1.3 M       1   1.4 M       1    12.0›
‹  total         1   1.3 M       -   529 K     0 B       0     0 B       0   1.8 M       1   1.4 M       1     3.5›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2   4.3 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        34   1.0 M   93.0%  (score == hit-rate)›
‹ tcache         1   616 B   99.8%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   79.5%  (score == utility)›
W210410 16:09:32.715638 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r34/1:‹/Table/3{8-9}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W210410 16:09:32.952857 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 16:09:33.361276 1 cli/start.go:736 ⋮ received signal 'terminated'
I210410 16:09:33.361508 1 cli/start.go:821 ⋮ initiating graceful shutdown of server
I210410 16:09:33.636874 476 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
I210410 16:09:33.726336 823 server/drain.go:174 ⋮ [server drain process] drain remaining: 1
I210410 16:09:33.726487 823 server/drain.go:176 ⋮ [server drain process] drain details: liveness record: 1
I210410 16:09:34.685123 823 server/drain.go:174 ⋮ [server drain process] drain remaining: 0
I210410 16:09:34.685180 823 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W210410 16:09:34.685218 477 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
W210410 16:09:34.685267 307 jobs/registry.go:675 ⋮ canceling all adopted jobs due to stopper quiescing
I210410 16:09:34.825935 1 cli/start.go:873 ⋮ server drained and shutdown completed
