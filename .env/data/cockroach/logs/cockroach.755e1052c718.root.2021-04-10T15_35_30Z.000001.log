I210410 15:35:30.895985 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/10 15:35:30
I210410 15:35:30.896035 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹755e1052c718›
I210410 15:35:30.896070 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)
I210410 15:35:30.896100 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start-single-node --http-port 26256 --insecure]›
I210410 15:35:30.896170 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W210410 15:35:30.895558 1 cli/start.go:1143 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I210410 15:35:30.896546 1 cli/start.go:1153 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I210410 15:35:30.897810 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
W210410 15:35:30.932326 1 cli/start.go:987 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (1.9 GiB).›
I210410 15:35:30.932852 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 15:35:30.932880 1 cli/start.go:1168 ⋮ ‹CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)›
I210410 15:35:30.967227 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 15:35:30.967262 1 server/config.go:428 ⋮ system total memory: ‹7.6 GiB›
I210410 15:35:30.967292 1 server/config.go:430 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   1.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210410 15:35:30.967363 1 cli/start.go:965 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I210410 15:35:30.967388 1 cli/start.go:972 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I210410 15:35:31.345948 1 cli/start.go:511 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I210410 15:35:31.346090 1 cli/start.go:516 ⋮ starting cockroach node
I210410 15:35:32.642562 83 server/server.go:790 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210410 15:35:34.634384 83 server/config.go:619 ⋮ [n?] 1 storage engine‹› initialized
I210410 15:35:34.650771 83 server/config.go:622 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I210410 15:35:34.650826 83 server/config.go:622 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
W210410 15:35:35.007854 83 cli/start.go:911 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"755e1052c718"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I210410 15:35:35.008026 165 server/server.go:1424 ⋮ [n1] connecting to gossip network to verify cluster ID ‹"dd9dc586-c756-4f4b-a9e5-9e23cf559418"›
I210410 15:35:35.008037 83 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"755e1052c718:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.7" started_at:1618068935008027337 cluster_name:"" sql_address:<network_field:"tcp" address_field:"755e1052c718:26257" >›
I210410 15:35:35.806451 165 server/server.go:1427 ⋮ [n1] node connected via gossip
W210410 15:35:35.907447 242 kv/kvserver/replica_range_lease.go:556 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 15:35:35.907806 242 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 15:35:35.961497 242 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 15:35:35.986156 83 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=196 GiB, available=4.3 GiB, used=6.8 MiB, logicalBytes=30 MiB), ranges=57, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=333.00 p90=50645.00 pMax=30315618.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
W210410 15:35:36.061628 242 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 15:35:36.249694 242 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 15:35:36.280201 83 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
I210410 15:35:36.453016 83 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210410 15:35:36.453266 83 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I210410 15:35:36.453524 83 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I210410 15:35:36.453661 83 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210410 15:35:36.453768 83 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210410 15:35:36.453826 83 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210410 15:35:36.453934 83 server/server.go:1544 ⋮ [n1] starting http server at ‹[::]:26256› (use: ‹755e1052c718:26256›)
I210410 15:35:36.454036 83 server/server.go:1551 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210410 15:35:36.454105 83 server/server.go:1552 ⋮ [n1] advertising CockroachDB node at ‹755e1052c718:26257›
I210410 15:35:37.192407 83 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I210410 15:35:37.297643 83 server/server_sql.go:800 ⋮ [n1] done ensuring all necessary migrations have run
I210410 15:35:37.297771 83 server/server.go:1887 ⋮ [n1] serving sql connections
I210410 15:35:37.298377 83 cli/start.go:677 ⋮ [config] clusterID: ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
I210410 15:35:37.298546 83 cli/start.go:687 ⋮ node startup completed:
CockroachDB node starting at 2021-04-10 15:35:37.298025931 +0000 UTC (took 6.5s)
build:               CCL v20.2.7 @ 2021/03/29 17:52:00 (go1.13.14)
webui:               ‹http://755e1052c718:26256›
sql:                 ‹postgresql://root@755e1052c718:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=755e1052c718:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp667338768›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
nodeID:              1
I210410 15:35:37.309502 343 sql/temporary_schema.go:510 ⋮ [n1] running temporary object cleanup background job
I210410 15:35:37.386066 327 jobs/job_scheduler.go:349 ⋮ [n1] waiting 4m0s before scheduled jobs daemon start
I210410 15:35:37.453154 168 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 15:35:37.700710 168 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
W210410 15:35:37.940275 209 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 15:35:37.954511 183 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
I210410 15:35:37.991481 328 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
I210410 15:35:38.419778 343 sql/temporary_schema.go:545 ⋮ [n1] found 0 temporary schemas
I210410 15:35:38.419900 343 sql/temporary_schema.go:548 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I210410 15:35:38.419968 343 sql/temporary_schema.go:549 ⋮ [n1] completed temporary object cleanup job
I210410 15:35:38.420025 343 sql/temporary_schema.go:627 ⋮ [n1] temporary object cleaner next scheduled to run at 2021-04-10 16:05:37.282102231 +0000 UTC
I210410 15:35:38.896829 339 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:755e1052c718:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.7 StartedAt:1618068935008027337 LocalityAddress:[] ClusterName: SQLAddress:755e1052c718:26257} ClusterID:dd9dc586-c756-4f4b-a9e5-9e23cf559418 StartedAt:1618068935008027337 LastUp:1618068902081535063}›
I210410 15:35:38.963907 341 sql/sqlliveness/slstorage/slstorage.go:348 ⋮ [n1] inserted sqlliveness session ‹6efa5623f2bb4b0e9acb0370d7716d63›
I210410 15:35:38.963997 341 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹6efa5623f2bb4b0e9acb0370d7716d63›
I210410 15:35:46.456123 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 207 goroutines, 25 MiB/96 MiB/46 MiB GO alloc/idle/total, 24 MiB/32 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (14x), 2.1 KiB/11 KiB (r/w)net
W210410 15:35:47.820970 224 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r106/1:‹/{Table/74-Max}›] handle raft ready: 1.0s [applied=2, batches=1, state_assertions=0]
I210410 15:35:56.175022 340 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
I210410 15:35:56.457637 30 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 1M 1 ]: 1M›
I210410 15:35:56.457858 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 207 goroutines, 23 MiB/97 MiB/46 MiB GO alloc/idle/total, 24 MiB/32 MiB CGO alloc/total, 13.5 CGO/sec, 3.6/1.1 %(u/s)time, 0.0 %gc (1x), 339 B/66 B (r/w)net
I210410 15:35:56.458001 30 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2   535 K       -   532 K       -       -       -       -   535 K       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   1.2 M       -   223 K     0 B       0     0 B       0   1.2 M       1   1.4 M       1     5.7›
‹  total         1   1.2 M       -   535 K     0 B       0     0 B       0   1.8 M       1   1.4 M       1     3.4›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2    16 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        30   948 K   94.6%  (score == hit-rate)›
‹ tcache         1   616 B   99.8%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   82.8%  (score == utility)›
I210410 15:36:06.458449 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 207 goroutines, 18 MiB/102 MiB/46 MiB GO alloc/idle/total, 24 MiB/32 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/0.8 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 15:36:16.459081 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 208 goroutines, 26 MiB/95 MiB/46 MiB GO alloc/idle/total, 24 MiB/32 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/0.9 %(u/s)time, 0.0 %gc (0x), 108 B/108 B (r/w)net
I210410 15:36:26.459380 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 208 goroutines, 22 MiB/98 MiB/48 MiB GO alloc/idle/total, 24 MiB/33 MiB CGO alloc/total, 0.5 CGO/sec, 4.1/0.8 %(u/s)time, 0.0 %gc (1x), 339 B/66 B (r/w)net
W210410 15:36:32.415880 201 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 15:36:35.661757 211 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 15:36:35.866439 189 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W210410 15:36:35.867084 144 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 15:36:36.073068 254 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.118409575s; err=<nil>
I210410 15:36:36.453406 31 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
  n1 [sentinel];
I210410 15:36:36.489959 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 155 MiB RSS, 210 goroutines, 31 MiB/90 MiB/48 MiB GO alloc/idle/total, 24 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.8/0.8 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
W210410 15:36:39.883740 1338 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r22/1:‹/Table/2{6-7}›] slow heartbeat took 1.066757939s; err=<nil>
I210410 15:36:40.785416 1382 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648801810479546369: stepping through state running with error: <nil>
I210410 15:36:42.238564 1382 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648801810479546369: stepping through state succeeded with error: <nil>
I210410 15:36:42.729575 1461 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648801820750086145: stepping through state running with error: <nil>
I210410 15:36:45.118405 1461 jobs/registry.go:1106 ⋮ [n1] AUTO CREATE STATS job 648801820750086145: stepping through state succeeded with error: <nil>
I210410 15:36:46.458805 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 207 goroutines, 20 MiB/98 MiB/51 MiB GO alloc/idle/total, 24 MiB/33 MiB CGO alloc/total, 0.5 CGO/sec, 11.5/1.7 %(u/s)time, 0.5 %gc (3x), 174 B/174 B (r/w)net
I210410 15:36:56.459178 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 207 goroutines, 29 MiB/91 MiB/51 MiB GO alloc/idle/total, 24 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/1.0 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 15:37:06.166881 1 cli/start.go:736 ⋮ received signal 'terminated'
I210410 15:37:06.167034 1 cli/start.go:821 ⋮ initiating graceful shutdown of server
I210410 15:37:06.457599 252 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 207 goroutines, 22 MiB/96 MiB/52 MiB GO alloc/idle/total, 24 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.3/0.7 %(u/s)time, 0.0 %gc (1x), 203 B/132 B (r/w)net
I210410 15:37:06.930023 1885 server/drain.go:174 ⋮ [server drain process] drain remaining: 4
I210410 15:37:06.930195 1885 server/drain.go:176 ⋮ [server drain process] drain details: descriptor leases: 3, liveness record: 1
I210410 15:37:08.578240 1885 server/drain.go:174 ⋮ [server drain process] drain remaining: 0
W210410 15:37:08.578200 208 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=2, batches=2, state_assertions=0]
I210410 15:37:08.578309 1885 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W210410 15:37:08.578379 341 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
W210410 15:37:08.578452 298 jobs/registry.go:675 ⋮ canceling all adopted jobs due to stopper quiescing
I210410 15:37:08.732672 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (gc): ‹node unavailable; try another peer›
I210410 15:37:08.733053 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (merge): ‹node unavailable; try another peer›
I210410 15:37:08.733186 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (split): ‹node unavailable; try another peer›
I210410 15:37:08.733268 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (replicate): ‹node unavailable; try another peer›
I210410 15:37:08.733338 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (replicaGC): ‹node unavailable; try another peer›
I210410 15:37:08.733404 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (raftlog): ‹node unavailable; try another peer›
I210410 15:37:08.733468 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (raftsnapshot): ‹node unavailable; try another peer›
I210410 15:37:08.733532 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (consistencyChecker): ‹node unavailable; try another peer›
I210410 15:37:08.733597 274 kv/kvserver/queue.go:582 ⋮ [n1,s1] rate limited in MaybeAdd (timeSeriesMaintenance): ‹node unavailable; try another peer›
W210410 15:37:08.794543 184 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 15:37:08.794800 253 ts/db.go:194 ⋮ [n1,ts-poll] error writing time series data: ‹result is ambiguous (server shutdown)›
I210410 15:37:09.139259 1 cli/start.go:873 ⋮ server drained and shutdown completed
