I210410 16:09:46.059600 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2021/04/10 16:09:46
I210410 16:09:46.059612 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹755e1052c718›
I210410 16:09:46.059622 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)
I210410 16:09:46.059628 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start-single-node --http-port 26256 --insecure]›
I210410 16:09:46.059639 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W210410 16:09:46.059504 1 cli/start.go:1143 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I210410 16:09:46.059727 1 cli/start.go:1153 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I210410 16:09:46.060084 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
W210410 16:09:46.060109 1 cli/start.go:987 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (1.9 GiB).›
I210410 16:09:46.060326 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 16:09:46.060355 1 cli/start.go:1168 ⋮ ‹CockroachDB CCL v20.2.7 (x86_64-unknown-linux-gnu, built 2021/03/29 17:52:00, go1.13.14)›
I210410 16:09:46.061491 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 7.6 GiB instead:›
I210410 16:09:46.061515 1 server/config.go:428 ⋮ system total memory: ‹7.6 GiB›
I210410 16:09:46.061539 1 server/config.go:430 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   1.9 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I210410 16:09:46.061611 1 cli/start.go:965 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I210410 16:09:46.061634 1 cli/start.go:972 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I210410 16:09:46.064417 1 cli/start.go:511 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I210410 16:09:46.064464 1 cli/start.go:516 ⋮ starting cockroach node
I210410 16:09:46.815235 44 server/server.go:790 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I210410 16:09:47.876223 44 server/config.go:619 ⋮ [n?] 1 storage engine‹› initialized
I210410 16:09:47.876271 44 server/config.go:622 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I210410 16:09:47.876292 44 server/config.go:622 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
W210410 16:09:47.955250 44 cli/start.go:911 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"755e1052c718"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I210410 16:09:47.955324 158 server/server.go:1424 ⋮ [n?] connecting to gossip network to verify cluster ID ‹"dd9dc586-c756-4f4b-a9e5-9e23cf559418"›
I210410 16:09:47.955509 44 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"755e1052c718:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.7" started_at:1618070987955494459 cluster_name:"" sql_address:<network_field:"tcp" address_field:"755e1052c718:26257" >›
W210410 16:09:47.962347 265 kv/kvserver/replica_range_lease.go:556 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 16:09:47.962493 158 server/server.go:1427 ⋮ [n1] node connected via gossip
W210410 16:09:47.962558 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 16:09:47.963782 44 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=196 GiB, available=4.3 GiB, used=6.5 MiB, logicalBytes=31 MiB), ranges=57, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=333.00 p90=52864.00 pMax=31730992.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I210410 16:09:47.963995 44 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
W210410 16:09:48.010546 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
W210410 16:09:48.109998 265 kv/kvserver/store.go:1691 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I210410 16:09:48.167440 44 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I210410 16:09:48.167669 44 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I210410 16:09:48.167945 44 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I210410 16:09:48.168057 44 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I210410 16:09:48.168155 44 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I210410 16:09:48.168215 44 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I210410 16:09:48.168312 44 server/server.go:1544 ⋮ [n1] starting http server at ‹[::]:26256› (use: ‹755e1052c718:26256›)
I210410 16:09:48.168473 44 server/server.go:1551 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I210410 16:09:48.168591 44 server/server.go:1552 ⋮ [n1] advertising CockroachDB node at ‹755e1052c718:26257›
I210410 16:09:49.444953 44 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I210410 16:09:49.445513 44 server/server_sql.go:800 ⋮ [n1] done ensuring all necessary migrations have run
I210410 16:09:49.445567 44 server/server.go:1887 ⋮ [n1] serving sql connections
I210410 16:09:49.445786 44 cli/start.go:677 ⋮ [config] clusterID: ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
I210410 16:09:49.445855 44 cli/start.go:687 ⋮ node startup completed:
CockroachDB node starting at 2021-04-10 16:09:49.445659238 +0000 UTC (took 3.4s)
build:               CCL v20.2.7 @ 2021/03/29 17:52:00 (go1.13.14)
webui:               ‹http://755e1052c718:26256›
sql:                 ‹postgresql://root@755e1052c718:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=755e1052c718:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp077086004›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹dd9dc586-c756-4f4b-a9e5-9e23cf559418›
nodeID:              1
I210410 16:09:49.447044 428 jobs/job_scheduler.go:349 ⋮ [n1] waiting 4m0s before scheduled jobs daemon start
I210410 16:09:49.452252 366 sql/temporary_schema.go:510 ⋮ [n1] running temporary object cleanup background job
I210410 16:09:49.454877 429 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
I210410 16:09:49.629030 126 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 16:09:49.936087 126 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
W210410 16:09:50.782420 466 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] slow heartbeat took 1.333549622s; err=<nil>
W210410 16:09:50.782894 255 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:09:50.949306 193 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r8/1:‹/Table/1{2-3}›] slow heartbeat took 1.500070496s; err=<nil>
W210410 16:09:51.183389 468 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r27/1:‹/{NamespaceTab…-Table/32}›] slow heartbeat took 1.731994775s; err=<nil>
W210410 16:09:51.250398 483 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] slow heartbeat took 1.796774787s; err=<nil>
I210410 16:09:51.284386 364 sql/sqlliveness/slstorage/slstorage.go:348 ⋮ [n1] inserted sqlliveness session ‹ae8d642387f342489af3717048af6dff›
I210410 16:09:51.284561 364 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹ae8d642387f342489af3717048af6dff›
W210410 16:09:51.317436 470 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] slow heartbeat took 1.862224842s; err=<nil>
I210410 16:09:51.319670 366 sql/temporary_schema.go:545 ⋮ [n1] found 0 temporary schemas
I210410 16:09:51.319776 366 sql/temporary_schema.go:548 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I210410 16:09:51.319819 366 sql/temporary_schema.go:549 ⋮ [n1] completed temporary object cleanup job
I210410 16:09:51.319854 366 sql/temporary_schema.go:627 ⋮ [n1] temporary object cleaner next scheduled to run at 2021-04-10 16:39:49.445550307 +0000 UTC
I210410 16:09:51.384793 362 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:755e1052c718:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.7 StartedAt:1618070987955494459 LocalityAddress:[] ClusterName: SQLAddress:755e1052c718:26257} ClusterID:dd9dc586-c756-4f4b-a9e5-9e23cf559418 StartedAt:1618070987955494459 LastUp:1618070974299482784}›
I210410 16:09:58.173486 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 137 MiB RSS, 207 goroutines, 29 MiB/28 MiB/42 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (14x), 25 KiB/37 KiB (r/w)net
I210410 16:10:08.172030 55 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 1M 1 ]: 1M›
I210410 16:10:08.172151 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 139 MiB RSS, 207 goroutines, 24 MiB/32 MiB/44 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 0.5 CGO/sec, 2.7/1.2 %(u/s)time, 0.0 %gc (1x), 503 B/66 B (r/w)net
I210410 16:10:08.172445 55 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         2   543 K       -   540 K       -       -       -       -   543 K       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   1.3 M       -    87 K     0 B       0     0 B       0   1.3 M       1   1.4 M       1    15.4›
‹  total         1   1.3 M       -   543 K     0 B       0     0 B       0   1.8 M       1   1.4 M       1     3.5›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         2   2.3 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        29   922 K   93.2%  (score == hit-rate)›
‹ tcache         1   616 B   99.8%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   85.1%  (score == utility)›
W210410 16:10:09.044819 228 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r17/1:‹/Table/2{1-2}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
I210410 16:10:18.172527 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 141 MiB RSS, 207 goroutines, 19 MiB/36 MiB/45 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 13.2 CGO/sec, 3.1/1.1 %(u/s)time, 0.0 %gc (1x), 203 B/0 B (r/w)net
I210410 16:10:28.172572 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 141 MiB RSS, 210 goroutines, 27 MiB/29 MiB/45 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/1.1 %(u/s)time, 0.0 %gc (0x), 136 B/66 B (r/w)net
I210410 16:10:28.401123 363 sql/sqlliveness/slstorage/slstorage.go:326 ⋮ [n1] deleted 1 expired SQL liveness sessions
W210410 16:10:29.725652 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.056413597s; err=<nil>
W210410 16:10:30.237796 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 16:10:38.172601 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 145 MiB RSS, 208 goroutines, 21 MiB/34 MiB/47 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/1.2 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:10:48.168006 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip connectivity
  n1 [sentinel];
I210410 16:10:48.172794 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 145 MiB RSS, 208 goroutines, 29 MiB/27 MiB/47 MiB GO alloc/idle/total, 11 MiB/21 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/2.0 %(u/s)time, 0.0 %gc (0x), 84 B/84 B (r/w)net
W210410 16:10:50.281107 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:10:50.281190 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:10:50.572048 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r24/1:‹/Table/2{8-9}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:10:50.572261 210 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:10:50.805863 1426 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r16/1:‹/Table/2{0-1}›] slow heartbeat took 1.353053029s; err=<nil>
I210410 16:10:58.174198 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 148 MiB RSS, 207 goroutines, 29 MiB/27 MiB/50 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.2 CGO/sec, 4.6/1.9 %(u/s)time, 0.0 %gc (1x), 405 B/132 B (r/w)net
I210410 16:11:08.173799 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 149 MiB RSS, 207 goroutines, 21 MiB/33 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/1.4 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:11:18.175214 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 149 MiB RSS, 207 goroutines, 30 MiB/26 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/1.5 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 16:11:28.174663 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 150 MiB RSS, 208 goroutines, 24 MiB/31 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/1.3 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
I210410 16:11:38.174080 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 151 MiB RSS, 208 goroutines, 32 MiB/24 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/1.3 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:11:48.167891 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:11:48.174500 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 208 goroutines, 26 MiB/29 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.6 %(u/s)time, 0.0 %gc (1x), 42 B/42 B (r/w)net
I210410 16:11:58.174514 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 207 goroutines, 20 MiB/33 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.8/1.7 %(u/s)time, 0.0 %gc (1x), 1.2 KiB/132 B (r/w)net
I210410 16:12:08.174456 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 152 MiB RSS, 207 goroutines, 28 MiB/27 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.4 %(u/s)time, 0.0 %gc (0x), 136 B/66 B (r/w)net
I210410 16:12:18.175864 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 207 goroutines, 20 MiB/34 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.2 %(u/s)time, 0.0 %gc (1x), 42 B/42 B (r/w)net
I210410 16:12:28.175563 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 153 MiB RSS, 208 goroutines, 29 MiB/27 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.7 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:12:38.173012 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 208 goroutines, 21 MiB/33 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/1.3 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:12:48.167940 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:12:48.175249 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 208 goroutines, 30 MiB/26 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/1.2 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:12:58.176292 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 207 goroutines, 23 MiB/32 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/1.8 %(u/s)time, 0.0 %gc (1x), 174 B/174 B (r/w)net
I210410 16:13:08.176977 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 207 goroutines, 31 MiB/25 MiB/51 MiB GO alloc/idle/total, 15 MiB/25 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.5 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:13:18.176617 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 154 MiB RSS, 207 goroutines, 23 MiB/31 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.2 CGO/sec, 2.2/1.5 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:13:28.177868 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 155 MiB RSS, 208 goroutines, 32 MiB/24 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.4 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:13:38.176962 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 208 goroutines, 22 MiB/32 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.3/1.5 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:13:48.168044 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:13:48.178097 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 156 MiB RSS, 208 goroutines, 30 MiB/26 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.3 %(u/s)time, 0.0 %gc (0x), 84 B/84 B (r/w)net
I210410 16:13:58.177574 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 207 goroutines, 25 MiB/30 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.0/1.5 %(u/s)time, 0.0 %gc (1x), 984 B/132 B (r/w)net
I210410 16:14:08.176760 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 157 MiB RSS, 207 goroutines, 33 MiB/24 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/0.9 %(u/s)time, 0.0 %gc (0x), 203 B/0 B (r/w)net
I210410 16:14:18.176732 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 207 goroutines, 24 MiB/29 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/1.1 %(u/s)time, 0.0 %gc (1x), 150 B/150 B (r/w)net
I210410 16:14:28.175642 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 158 MiB RSS, 208 goroutines, 33 MiB/23 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.0/1.2 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:14:38.177783 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 208 goroutines, 25 MiB/30 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.4 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:14:48.167994 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:14:48.177589 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 209 goroutines, 33 MiB/23 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/1.1 %(u/s)time, 0.0 %gc (0x), 220 B/150 B (r/w)net
I210410 16:14:58.177808 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 159 MiB RSS, 212 goroutines, 26 MiB/29 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 4.0/1.0 %(u/s)time, 0.0 %gc (1x), 132 B/132 B (r/w)net
I210410 16:15:08.176276 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 207 goroutines, 34 MiB/23 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 16:15:18.178795 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 207 goroutines, 26 MiB/29 MiB/53 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.1/1.2 %(u/s)time, 0.0 %gc (1x), 150 B/150 B (r/w)net
I210410 16:15:28.178969 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 160 MiB RSS, 208 goroutines, 34 MiB/22 MiB/53 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/1.2 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:15:38.177850 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 208 goroutines, 29 MiB/26 MiB/53 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/1.3 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:15:48.168122 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:15:48.178770 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 161 MiB RSS, 208 goroutines, 37 MiB/19 MiB/53 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.4 %(u/s)time, 0.0 %gc (0x), 150 B/150 B (r/w)net
I210410 16:15:58.179509 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 163 MiB RSS, 207 goroutines, 32 MiB/24 MiB/54 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 3.6/1.8 %(u/s)time, 0.0 %gc (1x), 918 B/66 B (r/w)net
I210410 16:16:08.179682 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 163 MiB RSS, 207 goroutines, 20 MiB/33 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.5 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:16:18.179905 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 163 MiB RSS, 207 goroutines, 28 MiB/27 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.6 %(u/s)time, 0.0 %gc (0x), 150 B/150 B (r/w)net
I210410 16:16:28.179787 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 164 MiB RSS, 208 goroutines, 20 MiB/33 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.8/1.4 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:16:38.178725 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 164 MiB RSS, 209 goroutines, 29 MiB/27 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/1.7 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 16:16:48.167886 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:16:48.178222 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 164 MiB RSS, 208 goroutines, 21 MiB/32 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.2 %(u/s)time, 0.0 %gc (1x), 150 B/150 B (r/w)net
I210410 16:16:58.180890 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 165 MiB RSS, 207 goroutines, 31 MiB/25 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.1 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:17:08.181150 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 165 MiB RSS, 207 goroutines, 23 MiB/31 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.9 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
W210410 16:17:09.970258 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:17:10.805880 206 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 16:17:10.809222 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W210410 16:17:11.055179 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.886199249s; err=<nil>
W210410 16:17:11.055614 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=2, batches=2, state_assertions=0]
I210410 16:17:18.181207 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 165 MiB RSS, 208 goroutines, 31 MiB/24 MiB/51 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/1.1 %(u/s)time, 0.0 %gc (0x), 150 B/150 B (r/w)net
I210410 16:17:28.182496 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 165 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.3 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:17:38.179338 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 166 MiB RSS, 208 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.3 %(u/s)time, 0.0 %gc (0x), 563 B/479 B (r/w)net
I210410 16:17:48.167856 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:17:48.179711 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 166 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 23 MiB/33 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.0 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:17:58.180006 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 166 MiB RSS, 207 goroutines, 32 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.2 CGO/sec, 2.2/1.1 %(u/s)time, 0.0 %gc (0x), 918 B/66 B (r/w)net
I210410 16:18:08.181935 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 167 MiB RSS, 209 goroutines, 24 MiB/30 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.6 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:18:18.181940 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 167 MiB RSS, 207 goroutines, 32 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.2 %(u/s)time, 0.0 %gc (0x), 585 B/42 B (r/w)net
I210410 16:18:28.181473 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 167 MiB RSS, 208 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.8 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
W210410 16:18:29.709842 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:18:30.259134 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:18:30.265115 205 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:18:30.616265 233 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:18:31.174345 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.00529835s; err=<nil>
I210410 16:18:38.180386 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 167 MiB RSS, 208 goroutines, 29 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/1.1 %(u/s)time, 0.0 %gc (0x), 132 B/132 B (r/w)net
I210410 16:18:48.167975 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:18:48.182116 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 168 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.6/1.1 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:18:58.180905 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 168 MiB RSS, 207 goroutines, 32 MiB/25 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.3 %(u/s)time, 0.0 %gc (0x), 108 B/108 B (r/w)net
I210410 16:19:08.181327 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 168 MiB RSS, 207 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.6/1.2 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:19:18.181184 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 168 MiB RSS, 207 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.0 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:19:28.181381 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 168 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/1.0 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
W210410 16:19:29.447802 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
I210410 16:19:38.185526 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 169 MiB RSS, 208 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.5 %(u/s)time, 0.0 %gc (0x), 202 B/132 B (r/w)net
I210410 16:19:48.167915 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:19:48.183046 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 169 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.9/1.1 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:19:58.182486 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 169 MiB RSS, 207 goroutines, 33 MiB/23 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/1.2 %(u/s)time, 0.0 %gc (0x), 960 B/108 B (r/w)net
I210410 16:20:08.172976 55 kv/kvserver/store.go:2625 ⋮ [n1,s1] sstables (read amplification = 1):
‹6 [ 1M 1 ]: 1M›
I210410 16:20:08.173373 55 kv/kvserver/store.go:2626 ⋮ [n1,s1] ‹›
‹__level_____count____size___score______in__ingest(sz_cnt)____move(sz_cnt)___write(sz_cnt)____read___r-amp___w-amp›
‹    WAL         5    16 M       -    16 M       -       -       -       -    16 M       -       -       -     1.0›
‹      0         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      1         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      2         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      3         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      4         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      5         0     0 B    0.00     0 B     0 B       0     0 B       0     0 B       0     0 B       0     0.0›
‹      6         1   1.3 M       -    87 K     0 B       0     0 B       0   1.3 M       1   1.4 M       1    15.4›
‹  total         1   1.3 M       -    16 M     0 B       0     0 B       0    17 M       1   1.4 M       1     1.1›
‹  flush         0›
‹compact         1     0 B          (size == estimated-debt)›
‹ memtbl         5    30 M›
‹zmemtbl         0     0 B›
‹   ztbl         0     0 B›
‹ bcache        31   986 K   98.4%  (score == hit-rate)›
‹ tcache         1   616 B  100.0%  (score == hit-rate)›
‹ titers         0›
‹ filter         -       -   85.1%  (score == utility)›
I210410 16:20:08.185466 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 170 MiB RSS, 207 goroutines, 24 MiB/30 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/1.7 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
W210410 16:20:10.517611 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 16:20:18.184284 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 170 MiB RSS, 207 goroutines, 32 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.1/1.6 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:20:28.184097 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 170 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/1.2 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
I210410 16:20:38.184099 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 171 MiB RSS, 208 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/1.1 %(u/s)time, 0.0 %gc (0x), 132 B/132 B (r/w)net
I210410 16:20:48.167937 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:20:48.184046 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 171 MiB RSS, 208 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.0 %(u/s)time, 0.0 %gc (1x), 0 B/0 B (r/w)net
I210410 16:20:58.183001 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 172 MiB RSS, 207 goroutines, 31 MiB/25 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/0.8 %(u/s)time, 0.0 %gc (0x), 108 B/108 B (r/w)net
I210410 16:21:08.185571 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 172 MiB RSS, 207 goroutines, 23 MiB/30 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/1.3 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:21:18.183645 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 172 MiB RSS, 207 goroutines, 31 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.4 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:21:28.185997 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 172 MiB RSS, 208 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 3.4/1.2 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
I210410 16:21:38.185793 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 172 MiB RSS, 208 goroutines, 29 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.5 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:21:48.167952 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:21:48.186009 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 173 MiB RSS, 208 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 3.2/0.9 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:21:58.185476 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 173 MiB RSS, 207 goroutines, 31 MiB/25 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/1.5 %(u/s)time, 0.0 %gc (0x), 960 B/108 B (r/w)net
I210410 16:22:08.185733 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 174 MiB RSS, 207 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/1.2 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:22:18.184974 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 174 MiB RSS, 207 goroutines, 31 MiB/25 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/1.2 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:22:28.186763 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 174 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.8/1.4 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
I210410 16:22:38.187594 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 208 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.5/1.8 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
I210410 16:22:48.168084 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:22:48.188050 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 208 goroutines, 22 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.0/1.7 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:22:58.187195 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 207 goroutines, 32 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/1.2 %(u/s)time, 0.0 %gc (0x), 108 B/108 B (r/w)net
I210410 16:23:08.185909 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 207 goroutines, 24 MiB/30 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/1.5 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:23:18.188354 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 207 goroutines, 32 MiB/24 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/1.2 %(u/s)time, 0.0 %gc (0x), 42 B/42 B (r/w)net
I210410 16:23:28.185958 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 175 MiB RSS, 208 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.5/1.2 %(u/s)time, 0.0 %gc (1x), 108 B/108 B (r/w)net
I210410 16:23:38.188268 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 176 MiB RSS, 209 goroutines, 29 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.3/1.0 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
W210410 16:23:38.230994 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:23:40.202055 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:40.202180 244 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 16:23:40.207770 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:23:42.502246 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.3s [applied=1, batches=1, state_assertions=0]
W210410 16:23:44.842260 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 4.6s [applied=1, batches=1, state_assertions=0]
W210410 16:23:44.842398 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 4.4s [applied=1, batches=1, state_assertions=0]
W210410 16:23:45.169760 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500660715s; err=‹aborted during DistSender.Send: context deadline exceeded›
W210410 16:23:45.169931 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) ‹aborted during DistSender.Send: context deadline exceeded›
Error types: (1) *contextutil.TimeoutError (2) *roachpb.internalError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:23:45.198970 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.6s [applied=1, batches=1, state_assertions=0]
W210410 16:23:45.199214 225 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 2.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:45.299285 127 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
W210410 16:23:45.588123 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:45.588305 231 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:45.588635 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:46.078037 256 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
W210410 16:23:46.411991 250 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:23:46.412224 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 16:23:46.790377 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:47.023926 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:23:47.357629 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.187519944s; err=<nil>
W210410 16:23:47.713907 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
I210410 16:23:48.167931 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
W210410 16:23:48.182121 10769 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] slow heartbeat took 2.933280352s; err=<nil>
I210410 16:23:48.188359 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 176 MiB RSS, 212 goroutines, 21 MiB/32 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.9/1.0 %(u/s)time, 0.0 %gc (1x), 1.4 KiB/66 B (r/w)net
W210410 16:23:48.940799 230 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:23:49.646191 10867 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 3.567888589s; err=<nil>
W210410 16:23:49.646503 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W210410 16:23:49.646497 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:23:50.526122 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:23:50.527983 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:23:50.905199 223 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r31/1:‹/Table/3{5-6}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 16:23:50.905183 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 16:23:51.444784 238 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:23:51.444853 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W210410 16:23:51.902251 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 16:23:51.902647 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:23:52.103503 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:23:52.409936 10855 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r5/1:‹/{Systemtse-Table/System…}›] slow heartbeat took 2.762756185s; err=<nil>
W210410 16:23:52.410521 226 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=0]
W210410 16:23:52.660938 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:23:52.752624 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.083593551s; err=<nil>
W210410 16:26:38.373868 127 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 16:26:40.120656 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 177 MiB RSS, 215 goroutines, 30 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.0 CGO/sec, 0.1/0.1 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
W210410 16:26:40.397399 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 16:26:41.065847 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W210410 16:26:41.466434 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:26:41.678690 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
I210410 16:26:41.975114 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618071829.502228631,0 is behind by 2m52.472880708s
W210410 16:26:42.091936 10902 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] slow heartbeat took 3.717601933s; err=<nil>
W210410 16:26:42.238897 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.863981917s; err=<nil>
W210410 16:26:42.693450 10837 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 3.318480076s; err=<nil>
I210410 16:26:42.832312 126 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 16:26:43.149989 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r26/1:‹/NamespaceTable/{30-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:26:43.428199 10839 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 3.741505176s; err=<nil>
W210410 16:26:43.428375 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:26:43.750999 10989 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 2.364884119s; err=<nil>
W210410 16:26:44.084953 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:26:44.085625 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:26:44.385963 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:26:44.653654 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:26:44.653710 259 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:26:44.659770 248 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=0]
W210410 16:26:45.121606 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 2.882564938s; err=<nil>
W210410 16:26:45.121751 11026 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r40/1:‹/Table/5{4-5}›] slow heartbeat took 2.74941394s; err=<nil>
I210410 16:26:50.121394 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 177 MiB RSS, 207 goroutines, 22 MiB/31 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.2/1.3 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:27:00.122036 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 207 goroutines, 30 MiB/25 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.7/1.3 %(u/s)time, 0.0 %gc (0x), 287 B/84 B (r/w)net
I210410 16:27:10.121804 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 208 goroutines, 20 MiB/33 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.7/1.1 %(u/s)time, 0.0 %gc (1x), 66 B/66 B (r/w)net
I210410 16:27:20.120809 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 208 goroutines, 28 MiB/27 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.1/1.2 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
W210410 16:27:26.923873 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 5.822322052s; err=context deadline exceeded
W210410 16:27:26.924078 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 6.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:26.924059 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:26.924188 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 5.5s [applied=1, batches=1, state_assertions=0]
W210410 16:27:26.924178 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 5.5s [applied=1, batches=1, state_assertions=0]
W210410 16:27:26.929164 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 5.5s [applied=1, batches=1, state_assertions=0]
W210410 16:27:29.784967 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 7.6s [applied=1, batches=1, state_assertions=0]
I210410 16:27:29.955289 1 cli/start.go:736 ⋮ received signal 'terminated'
I210410 16:27:29.955434 1 cli/start.go:821 ⋮ initiating graceful shutdown of server
I210410 16:27:30.100441 56 gossip/gossip.go:568 ⋮ [n1] gossip status (ok, 1 node‹›)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 0/0 sent/received, bytes 0B/0B sent/received)
I210410 16:27:30.121672 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 234 goroutines, 36 MiB/20 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.2/1.4 %(u/s)time, 0.0 %gc (0x), 66 B/66 B (r/w)net
W210410 16:27:31.277060 257 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 4.3s [applied=1, batches=1, state_assertions=0]
W210410 16:27:31.277096 236 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 4.4s [applied=1, batches=1, state_assertions=0]
W210410 16:27:31.277738 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 4.4s [applied=2, batches=2, state_assertions=0]
W210410 16:27:31.278039 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 4.4s [applied=3, batches=2, state_assertions=0]
W210410 16:27:31.424370 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500113995s; err=context deadline exceeded
W210410 16:27:31.424501 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:32.792478 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 3.0s [applied=6, batches=1, state_assertions=0]
W210410 16:27:32.792885 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.9s [applied=1, batches=1, state_assertions=0]
W210410 16:27:33.693909 222 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 16:27:33.693984 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.4s [applied=1, batches=1, state_assertions=0]
W210410 16:27:34.761594 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:34.761640 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
I210410 16:27:34.777251 126 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I210410 16:27:34.955716 11535 cli/start.go:831 ⋮ 53 running tasks
W210410 16:27:35.924817 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500210103s; err=context deadline exceeded
W210410 16:27:35.925030 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:38.398496 127 kv/kvserver/closedts/provider/provider.go:155 ⋮ [ct-closer] unable to move closed timestamp forward: not live
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:61
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) not live
Error types: (1) *withstack.withStack (2) *errutil.leafError
I210410 16:27:39.955679 11535 cli/start.go:831 ⋮ 55 running tasks
I210410 16:27:40.122304 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 235 goroutines, 25 MiB/28 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 2.4/0.8 %(u/s)time, 0.0 %gc (1x), 287 B/216 B (r/w)net
W210410 16:27:40.425328 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500139308s; err=context deadline exceeded
W210410 16:27:40.425520 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:41.940771 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 8.0s [applied=1, batches=1, state_assertions=0]
I210410 16:27:41.970610 126 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
W210410 16:27:42.844147 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 8.1s [applied=1, batches=1, state_assertions=0]
W210410 16:27:42.844136 214 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 8.1s [applied=1, batches=1, state_assertions=0]
W210410 16:27:43.289087 199 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:44.067303 11467 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] slow heartbeat took 17.679847014s; err=<nil>
W210410 16:27:44.925839 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500168401s; err=context deadline exceeded
W210410 16:27:44.942291 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

I210410 16:27:44.955663 11535 cli/start.go:831 ⋮ 50 running tasks
W210410 16:27:45.012881 11546 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 18.088022042s; err=heartbeat failed on epoch increment
E210410 16:27:45.013008 11546 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] heartbeat failed on epoch increment
W210410 16:27:46.046986 204 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:46.991782 11533 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 20.062621005s; err=heartbeat failed on epoch increment
E210410 16:27:46.991878 11533 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] heartbeat failed on epoch increment
W210410 16:27:47.814475 11583 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 17.91937709s; err=heartbeat failed on epoch increment
E210410 16:27:47.814592 11583 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] heartbeat failed on epoch increment
W210410 16:27:48.794495 11550 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 17.516684099s; err=heartbeat failed on epoch increment
E210410 16:27:48.794619 11550 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] heartbeat failed on epoch increment
W210410 16:27:49.442685 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.50020394s; err=context deadline exceeded
W210410 16:27:49.622753 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:49.706230 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
I210410 16:27:49.955702 11535 cli/start.go:831 ⋮ 49 running tasks
I210410 16:27:50.120276 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 178 MiB RSS, 233 goroutines, 27 MiB/26 MiB/52 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 0.3/1.0 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
W210410 16:27:50.384438 11593 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] slow heartbeat took 17.591188733s; err=heartbeat failed on epoch increment
E210410 16:27:50.384549 11593 kv/kvserver/replica_range_lease.go:340 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] heartbeat failed on epoch increment
W210410 16:27:50.951893 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:52.564711 206 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:27:53.153871 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:27:53.731939 197 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
I210410 16:27:54.003548 270 kv/kvserver/replica_rangefeed.go:610 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] RangeFeed closed timestamp 1618072037.993648660,0 is behind by 36.009895084s
W210410 16:27:54.123247 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.500125356s; err=context deadline exceeded
W210410 16:27:54.254099 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:54.332572 253 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:54.799410 11509 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] slow heartbeat took 9.786210953s; err=<nil>
W210410 16:27:54.799471 197 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:27:54.799495 11695 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] slow heartbeat took 8.752377424s; err=<nil>
W210410 16:27:54.799592 11510 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] slow heartbeat took 7.807456852s; err=<nil>
W210410 16:27:54.799669 11810 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] slow heartbeat took 6.98485018s; err=<nil>
W210410 16:27:54.799753 11512 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] slow heartbeat took 6.004928419s; err=<nil>
I210410 16:27:54.955689 11535 cli/start.go:831 ⋮ 49 running tasks
W210410 16:27:55.500093 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:27:55.967069 11712 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] slow heartbeat took 5.537483987s; err=<nil>
W210410 16:27:55.967139 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:55.967166 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:55.967158 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:55.967410 208 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.590254 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.935910 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.935996 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r32/1:‹/Table/3{6-7}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.936016 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.936108 208 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:56.936177 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:58.159064 200 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.6s [applied=2, batches=2, state_assertions=0]
W210410 16:27:58.849395 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W210410 16:27:58.849459 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 1.9s [applied=2, batches=1, state_assertions=0]
W210410 16:27:58.849812 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
I210410 16:27:58.850091 62 kv/kvserver/node_liveness.go:1131 ⋮ [n1,liveness-hb] retrying liveness update after ‹kvserver.errRetryLiveness›: ‹result is ambiguous (context deadline exceeded)›
W210410 16:27:58.850381 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 4.59605801s; err=context deadline exceeded
W210410 16:27:58.850516 62 kv/kvserver/node_liveness.go:650 ⋮ [n1,liveness-hb] failed node liveness heartbeat: ‹operation "node liveness heartbeat" timed out after 4.5s›
(1) ‹operation "node liveness heartbeat" timed out after 4.5s›
Wraps: (2) context deadline exceeded
Error types: (1) *contextutil.TimeoutError (2) context.deadlineExceededError

An inability to maintain liveness will prevent a node from participating in a
cluster. If this problem persists, it may be a sign of resource starvation or
of network connectivity problems. For help troubleshooting, visit:

    https://www.cockroachlabs.com/docs/stable/cluster-setup-troubleshooting.html#node-liveness-issues

W210410 16:27:58.855397 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.9s [applied=2, batches=2, state_assertions=0]
W210410 16:27:59.185154 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 1.0s [applied=1, batches=1, state_assertions=0]
W210410 16:27:59.664532 11804 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r43/1:‹/Table/5{5-6}›] slow heartbeat took 3.697076364s; err=<nil>
W210410 16:27:59.664677 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:27:59.665032 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.8s [applied=3, batches=1, state_assertions=0]
W210410 16:27:59.665236 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=2, batches=2, state_assertions=0]
W210410 16:27:59.665457 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:27:59.665797 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
I210410 16:27:59.955642 11535 cli/start.go:831 ⋮ 31 running tasks
W210410 16:27:59.976483 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
I210410 16:28:00.120704 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 179 MiB RSS, 219 goroutines, 20 MiB/32 MiB/53 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.4/1.0 %(u/s)time, 0.0 %gc (1x), 1.1 KiB/0 B (r/w)net
W210410 16:28:00.422656 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.422746 216 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.422894 204 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r43/1:‹/Table/5{5-6}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.422918 198 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.422978 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.429727 217 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:00.712687 237 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.068514 249 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.068588 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.068530 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.068650 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.602337 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.914218 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 3.063420584s; err=<nil>
W210410 16:28:01.914272 219 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r7/1:‹/Table/1{1-2}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.914295 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.914272 215 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W210410 16:28:01.914384 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:28:02.216895 252 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:02.459885 11872 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r46/1:‹/Table/5{6-7}›] slow heartbeat took 2.036316642s; err=<nil>
W210410 16:28:02.460016 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:28:02.460053 220 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r3/1:‹/System/{NodeLive…-tsd}›] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W210410 16:28:02.816126 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:03.094439 213 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:03.094733 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r46/1:‹/Table/5{6-7}›] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W210410 16:28:04.572952 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r4/1:‹/System{/tsd-tse}›] handle raft ready: 1.8s [applied=1, batches=1, state_assertions=0]
I210410 16:28:04.955710 11535 cli/start.go:831 ⋮ 22 running tasks
W210410 16:28:04.976478 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W210410 16:28:04.977069 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 1.9s [applied=2, batches=2, state_assertions=0]
W210410 16:28:07.045161 240 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r1/1:‹/{Min-System/NodeL…}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 16:28:07.045162 207 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r2/1:‹/System/NodeLiveness{-Max}›] handle raft ready: 2.1s [applied=1, batches=1, state_assertions=0]
W210410 16:28:07.167693 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 5.253396594s; err=<nil>
W210410 16:28:07.167807 254 kv/kvserver/store_raft.go:493 ⋮ [n1,s1,r35/1:‹/Table/{39-53}›] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W210410 16:28:07.390246 12003 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r84/1:‹/Table/6{8-9}›] slow heartbeat took 4.294882392s; err=<nil>
I210410 16:28:07.869327 11534 server/drain.go:174 ⋮ [server drain process] drain remaining: 5
I210410 16:28:07.869386 11534 server/drain.go:176 ⋮ [server drain process] drain details: SQL clients: 1, descriptor leases: 3, liveness record: 1
W210410 16:28:08.492194 62 kv/kvserver/node_liveness.go:748 ⋮ [n1,liveness-hb] slow heartbeat took 1.324413448s; err=<nil>
W210410 16:28:09.772636 12049 kv/kvserver/node_liveness.go:748 ⋮ [n1,s1,r18/1:‹/Table/2{2-3}›] slow heartbeat took 1.001363569s; err=<nil>
I210410 16:28:09.955583 11535 cli/start.go:831 ⋮ 20 running tasks
I210410 16:28:10.120583 60 server/status/runtime.go:525 ⋮ [n1] runtime stats: 179 MiB RSS, 212 goroutines, 29 MiB/26 MiB/53 MiB GO alloc/idle/total, 39 MiB/49 MiB CGO alloc/total, 0.1 CGO/sec, 1.2/0.8 %(u/s)time, 0.0 %gc (0x), 0 B/0 B (r/w)net
I210410 16:28:11.031346 11534 server/drain.go:174 ⋮ [server drain process] drain remaining: 3
I210410 16:28:11.031382 11534 server/drain.go:176 ⋮ [server drain process] drain details: descriptor leases: 3
I210410 16:28:12.937197 11534 server/drain.go:174 ⋮ [server drain process] drain remaining: 0
I210410 16:28:12.937308 11534 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W210410 16:28:12.937436 423 jobs/registry.go:675 ⋮ canceling all adopted jobs due to stopper quiescing
W210410 16:28:13.037378 364 kv/txn.go:618 ⋮ [n1] failure aborting transaction: ‹node unavailable; try another peer›; abort caused by: ‹result is ambiguous (context canceled)›
W210410 16:28:13.037592 364 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
I210410 16:28:13.277952 1 cli/start.go:873 ⋮ server drained and shutdown completed
